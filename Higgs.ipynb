{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/llayer/ml_exercise/blob/master/Higgs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPBJ_Fkqatao"
   },
   "source": [
    "# Higgs ML dataset studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYiLaejiY1wO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7E8GpkJsZeeD",
    "outputId": "9e13fca5-b374-4e28-8b83-40f5a83eda7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ml_exercise' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/llayer/ml_exercise\n",
    "#!pip3 install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sx6G1hOJJ5EU",
    "outputId": "49f0970e-ec43-44c4-b184-d68098343a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_exercise  sample_data  xgboost.h5\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCPA968mZ4t8"
   },
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fgl4De_IY1wf"
   },
   "outputs": [],
   "source": [
    "sig = pd.read_hdf('higgs_signal.h5')\n",
    "bkg = pd.read_hdf('higgs_bkg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "Sp7TCQ6OY1wp",
    "outputId": "5cbd3b57-8425-4154-811f-a68a1eb36f7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton_pT</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet1_pt</th>\n",
       "      <th>jet1_eta</th>\n",
       "      <th>jet1_phi</th>\n",
       "      <th>jet1_btag</th>\n",
       "      <th>jet2_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>jet4_phi</th>\n",
       "      <th>jet4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.723801</td>\n",
       "      <td>-0.914611</td>\n",
       "      <td>0.910944</td>\n",
       "      <td>1.194830</td>\n",
       "      <td>-0.448292</td>\n",
       "      <td>0.839489</td>\n",
       "      <td>-0.871428</td>\n",
       "      <td>0.587799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.916982</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.867059</td>\n",
       "      <td>1.127180</td>\n",
       "      <td>1.211664</td>\n",
       "      <td>0.695883</td>\n",
       "      <td>0.694068</td>\n",
       "      <td>0.755813</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.974119</td>\n",
       "      <td>0.660297</td>\n",
       "      <td>-1.362428</td>\n",
       "      <td>1.234102</td>\n",
       "      <td>1.677716</td>\n",
       "      <td>1.478815</td>\n",
       "      <td>0.408940</td>\n",
       "      <td>-0.105273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.017048</td>\n",
       "      <td>...</td>\n",
       "      <td>1.604089</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.938668</td>\n",
       "      <td>1.233898</td>\n",
       "      <td>0.990063</td>\n",
       "      <td>0.524871</td>\n",
       "      <td>0.900614</td>\n",
       "      <td>0.917613</td>\n",
       "      <td>1.083369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946889</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>1.210014</td>\n",
       "      <td>0.343294</td>\n",
       "      <td>-1.579545</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>1.030804</td>\n",
       "      <td>-0.475041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558635</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.881641</td>\n",
       "      <td>0.845381</td>\n",
       "      <td>0.997408</td>\n",
       "      <td>0.695120</td>\n",
       "      <td>0.787132</td>\n",
       "      <td>0.657668</td>\n",
       "      <td>0.721147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.298084</td>\n",
       "      <td>-0.897079</td>\n",
       "      <td>1.224441</td>\n",
       "      <td>0.618091</td>\n",
       "      <td>0.856746</td>\n",
       "      <td>0.493122</td>\n",
       "      <td>-0.021810</td>\n",
       "      <td>-1.520042</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.973234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848238</td>\n",
       "      <td>0.925814</td>\n",
       "      <td>0.973957</td>\n",
       "      <td>0.961469</td>\n",
       "      <td>0.946147</td>\n",
       "      <td>1.028120</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.022289</td>\n",
       "      <td>-0.481195</td>\n",
       "      <td>0.169649</td>\n",
       "      <td>1.103255</td>\n",
       "      <td>0.744424</td>\n",
       "      <td>1.648197</td>\n",
       "      <td>-0.780327</td>\n",
       "      <td>-1.484007</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.675472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284934</td>\n",
       "      <td>1.550981</td>\n",
       "      <td>0.717778</td>\n",
       "      <td>0.752909</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>1.648921</td>\n",
       "      <td>1.138676</td>\n",
       "      <td>1.118826</td>\n",
       "      <td>0.977200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lepton_pT  lepton_eta  lepton_phi  missing_energy_magnitude  \\\n",
       "0   0.723801   -0.914611    0.910944                  1.194830   \n",
       "1   1.974119    0.660297   -1.362428                  1.234102   \n",
       "2   0.946889    0.169416    1.210014                  0.343294   \n",
       "3   1.298084   -0.897079    1.224441                  0.618091   \n",
       "4   1.022289   -0.481195    0.169649                  1.103255   \n",
       "\n",
       "   missing_energy_phi   jet1_pt  jet1_eta  jet1_phi  jet1_btag   jet2_pt  ...  \\\n",
       "0           -0.448292  0.839489 -0.871428  0.587799   0.000000  0.654446  ...   \n",
       "1            1.677716  1.478815  0.408940 -0.105273   0.000000  1.017048  ...   \n",
       "2           -1.579545  0.999435  1.030804 -0.475041   0.000000  0.435374  ...   \n",
       "3            0.856746  0.493122 -0.021810 -1.520042   2.173076  0.973234  ...   \n",
       "4            0.744424  1.648197 -0.780327 -1.484007   2.173076  0.675472  ...   \n",
       "\n",
       "   jet4_phi  jet4_btag      m_jj     m_jjj      m_lv     m_jlv      m_bb  \\\n",
       "0 -0.916982   3.101961  0.867059  1.127180  1.211664  0.695883  0.694068   \n",
       "1  1.604089   3.101961  1.938668  1.233898  0.990063  0.524871  0.900614   \n",
       "2  0.558635   3.101961  0.881641  0.845381  0.997408  0.695120  0.787132   \n",
       "3  0.581386   0.000000  0.848238  0.925814  0.973957  0.961469  0.946147   \n",
       "4 -0.284934   1.550981  0.717778  0.752909  0.996800  1.648921  1.138676   \n",
       "\n",
       "      m_wbb    m_wwbb  label  \n",
       "0  0.755813  0.761658      0  \n",
       "1  0.917613  1.083369      0  \n",
       "2  0.657668  0.721147      0  \n",
       "3  1.028120  0.848133      0  \n",
       "4  1.118826  0.977200      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4WBvBRsY1wy"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([sig, bkg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KnoSsoG8df2h"
   },
   "source": [
    "### Split data in train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7y4nYcXHde4t"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prep_data(data, val_size = 0.3):\n",
    "\n",
    "\n",
    "    X_train, X_val = train_test_split(data, test_size = val_size, stratify = data['label'], random_state = 0)\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "X_train, X_val = prep_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "14000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "print( len(data) )\n",
    "print( len(X_train) )\n",
    "print( len(X_val) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fz6Kr_wHbLCn"
   },
   "source": [
    "## 2. Feature importance with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1szgLItqcDqx"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "def get_feature_importance(data):\n",
    "\n",
    "    features = data.drop(['label'], axis=1).values\n",
    "    labels = data[['label']].values.ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping_rounds = 5\n",
    "\n",
    "    # Define model\n",
    "    model_bdt = xgb.XGBClassifier(n_jobs = 4)\n",
    "\n",
    "    # Last in list is used for early stopping\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "    # Fit with early stopping\n",
    "    model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
    "                early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "    \n",
    "    plot_importance(model_bdt)\n",
    "    fscore = list(model_bdt.feature_importances_)\n",
    "    feature_importance = pd.DataFrame(list(data.drop(['label'], axis=1)))\n",
    "    feature_importance['f-score'] = fscore\n",
    "    feature_importance.columns = ['feature', 'fscore']\n",
    "    feature_importance = feature_importance.sort_values(by=['fscore'], ascending=False)\n",
    "\n",
    "    return feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "UCyOAN21cgh-",
    "outputId": "ede8c6b9-1398-45cd-ea63-584f9c65b0e4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = get_feature_importance(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "_REzjOrwdDFd",
    "outputId": "77f55658-2185-4c50-8257-b8c22a572b03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>m_bb</td>\n",
       "      <td>0.148234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>m_wbb</td>\n",
       "      <td>0.080355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>m_wwbb</td>\n",
       "      <td>0.074038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>m_jjj</td>\n",
       "      <td>0.069354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jet1_pt</td>\n",
       "      <td>0.061405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature    fscore\n",
       "25     m_bb  0.148234\n",
       "26    m_wbb  0.080355\n",
       "27   m_wwbb  0.074038\n",
       "22    m_jjj  0.069354\n",
       "5   jet1_pt  0.061405"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWiqfCYZdxai"
   },
   "source": [
    "## Test algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTY8ZTRaeIbK"
   },
   "source": [
    "### Set up Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JadlZZmLd7O-"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import skopt\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def fit_rf(X_train, y_train, X_test, y_test, p):\n",
    "    \n",
    "    clf = rfc = RandomForestClassifier(n_estimators=p['n_estimators'], max_depth = p['max_depth'],  \n",
    "              min_samples_split = p['min_samples_split'], min_samples_leaf = p['min_samples_leaf'],\n",
    "                                       random_state=42, n_jobs=4).fit(X_train, y_train)\n",
    "    predictions = clf.predict_proba(X_test)[:,1]\n",
    "    return y_test, predictions    \n",
    "    \n",
    "    \n",
    "\n",
    "def fit_lreg(X_train, y_train, X_test, y_test, p):\n",
    "\n",
    "    clf = LogisticRegression(random_state=0, C = p['C']).fit(X_train, y_train)\n",
    "    predictions = clf.predict_proba(X_test)[:,1]\n",
    "    return y_test, predictions\n",
    "\n",
    "\n",
    "def fit_xgboost(X_train, y_train, X_test, y_test, p):\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping_rounds = 10\n",
    "    # Define model\n",
    "    model_bdt = xgb.XGBClassifier(n_jobs = 4, n_estimators = int(p['n_estimators']), learning_rate = p['learning_rate'],\n",
    "                            max_depth = int(p['max_depth']), min_child_weight = int(p['min_child_weight']))\n",
    "    # Last in list is used for early stopping\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    # Fit with early stopping\n",
    "    #model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
    "    #                early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "    model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"])\n",
    "    predictions = model_bdt.predict_proba(X_test)[:,1]\n",
    "    return y_test, predictions\n",
    "\n",
    "def fit_keras(X_train, y_train, X_test, y_test, p):\n",
    "\n",
    "    # Early stopping\n",
    "    patience = 5\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=patience)\n",
    "    \n",
    "    # Define model\n",
    "    model = create_model(X_train.shape[1], p['dense_layers'], p['dense_units'], 0., \n",
    "                            #p['regulizer_value'], \n",
    "                            p['dropout_value'], \n",
    "                            p['learning_rate'])\n",
    "    \n",
    "    #history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100,# p['batch_size'], \n",
    "    #                    epochs=1000, verbose=0, callbacks=[es])\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size = p['batch_size'], epochs=p['epochs'], verbose=0)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    return y_test, predictions\n",
    "\n",
    "\n",
    "def optimize( algo, dimensions, initial_param, data, cv = False, kfold_splits = 5, num_calls=12, random_state = 42): \n",
    "\n",
    "    prior_values = []\n",
    "    prior_names = []\n",
    "    for var in dimensions:\n",
    "        name = var.name\n",
    "        print( name )\n",
    "        prior_names.append(name)\n",
    "        prior_values.append(initial_param[name])\n",
    "\n",
    "    global num_skopt_call\n",
    "    num_skopt_call = 0\n",
    "    #errors = []\n",
    "    \n",
    "    cv_results = []\n",
    "\n",
    "    @use_named_args(dimensions)\n",
    "    def fitness(**p): \n",
    "\n",
    "        global num_skopt_call\n",
    "\n",
    "        print('\\n \\t ::: {} SKOPT CALL ::: \\n'.format(num_skopt_call+1))\n",
    "        print(p)\n",
    "\n",
    "        reduced_feat = feature_importance.iloc[0:p['n_feat']]\n",
    "        reduced_feat = list(reduced_feat['feature'])\n",
    "        data_red = data[reduced_feat]\n",
    "        features = data_red.values\n",
    "        labels = data[['label']].values.ravel()\n",
    "\n",
    "        if cv == False:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=random_state)\n",
    "            if algo == 'xgboost':\n",
    "                y_test, y_pred = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
    "            if algo == 'keras':\n",
    "                y_test, y_pred = fit_keras(X_train, y_train, X_test, y_test, p)\n",
    "            if algo == 'lreg':\n",
    "                y_test, y_pred = fit_lreg(X_train, y_train, X_test, y_test, p)\n",
    "            if algo == 'rf':\n",
    "                y_test, y_pred = fit_rf(X_train, y_train, X_test, y_test, p)\n",
    "            score = roc_auc_score(y_test, y_pred )\n",
    "            print(score)\n",
    "\n",
    "        else:\n",
    "            cv_scores = []    \n",
    "            enum = enumerate(KFold(n_splits=kfold_splits, shuffle=True, random_state=random_state).split(features,labels))\n",
    "            for i,(index_train, index_valid) in enum:\n",
    "                X_train, X_test = features[ index_train ], features[ index_valid ]\n",
    "                y_train, y_test = labels[ index_train ], labels[ index_valid ]   \n",
    "                if algo == 'xgboost':\n",
    "                    y_test, y_pred  = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
    "                if algo == 'keras':\n",
    "                    y_test, y_pred  = fit_keras(X_train, y_train, X_test, y_test, p)\n",
    "                if algo == 'lreg':\n",
    "                    y_test, y_pred = fit_lreg(X_train, y_train, X_test, y_test, p)\n",
    "                if algo == 'rf':\n",
    "                    y_test, y_pred = fit_rf(X_train, y_train, X_test, y_test, p)\n",
    "                score = roc_auc_score(y_test, y_pred )\n",
    "                print(score)\n",
    "                cv_scores.append(score)\n",
    "                #print( cv_scores )\n",
    "            score = np.mean(cv_scores)\n",
    "            std = np.std(cv_scores)\n",
    "            cv_results.append((num_skopt_call, std))\n",
    "            print(score)\n",
    "            print(std)\n",
    "\n",
    "        num_skopt_call += 1\n",
    "\n",
    "        return -1*score\n",
    "\n",
    "    search_result = gp_minimize( func = fitness, dimensions = dimensions,\n",
    "                                 acq_func = 'EI', # Expected Improvement\n",
    "                                 n_calls = num_calls, x0 = prior_values )\n",
    "\n",
    "    params = pd.DataFrame(search_result['x_iters'])\n",
    "    params.columns = [*prior_names]\n",
    "    params = params.rename_axis('call').reset_index()\n",
    "    scores = pd.DataFrame(search_result['func_vals'])\n",
    "    scores.columns = ['score']\n",
    "    result = pd.concat([params, scores], axis=1)\n",
    "    result = result.sort_values(by=['score'])\n",
    "    #errors_frame = pd.DataFrame(errors, columns = ['call', 'q_error', 't_error'])\n",
    "    #result = pd.merge(result, errors_frame, on=['call']) \n",
    "    \n",
    "    if cv_results is not None:\n",
    "        cv_frame = pd.DataFrame(cv_results, columns = ['call', 'std'])\n",
    "        result = pd.merge(result, cv_frame, on=['call'])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r236T_l7d2AK"
   },
   "source": [
    "### 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Oz0bOrMdCs3"
   },
   "outputs": [],
   "source": [
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Skopt dimensions\n",
    "skopt_dims = [       \n",
    "    Integer(        low=100,    high=1000,                         name='n_estimators'     ),\n",
    "    Real(        low=1e-2, high=1,     prior='log-uniform', name='learning_rate'     ),\n",
    "    Integer(        low=2,    high=25,                         name='max_depth'     ),\n",
    "    Integer(        low=1,    high=25,                         name='min_child_weight'     ),\n",
    "    Real(        low=1e-6, high=1e-2,     prior='log-uniform', name='reg_alpha'     ),\n",
    "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
    "\n",
    "]\n",
    "\n",
    "# Initial parameters\n",
    "init_param = {'n_estimators' : 100, 'learning_rate' : 0.3, 'reg_alpha' : 1e-5, 'max_depth' : 6, 'min_child_weight' : 1, 'n_feat':12 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZUaHPgdeevWs",
    "outputId": "35d3ea31-76b2-441b-9ef0-e9cc87b4794b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators\n",
      "learning_rate\n",
      "max_depth\n",
      "min_child_weight\n",
      "reg_alpha\n",
      "n_feat\n",
      "\n",
      " \t ::: 1 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 6, 'min_child_weight': 1, 'reg_alpha': 1e-05, 'n_feat': 12}\n",
      "0.7783481905974743\n",
      "0.756554135135797\n",
      "0.7831935302821571\n",
      "0.7820349578088368\n",
      "0.766658876263219\n",
      "0.7733579380174967\n",
      "0.010238919749100243\n",
      "\n",
      " \t ::: 2 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 871, 'learning_rate': 0.5524950139780906, 'max_depth': 22, 'min_child_weight': 24, 'reg_alpha': 8.638251346421589e-05, 'n_feat': 21}\n",
      "0.7504984734569262\n",
      "0.7475994701997568\n",
      "0.761080157150875\n",
      "0.7572154853413278\n",
      "0.75337938516367\n",
      "0.7539545942625112\n",
      "0.0047764065046249846\n",
      "\n",
      " \t ::: 3 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 620, 'learning_rate': 0.1943929417079289, 'max_depth': 8, 'min_child_weight': 14, 'reg_alpha': 0.0002506676081734915, 'n_feat': 19}\n",
      "0.7688644397097119\n",
      "0.7676945322002628\n",
      "0.7822195009949486\n",
      "0.7740853135542686\n",
      "0.7656980031392944\n",
      "0.7717123579196972\n",
      "0.005940656514469035\n",
      "\n",
      " \t ::: 4 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 613, 'learning_rate': 0.10893363672774736, 'max_depth': 10, 'min_child_weight': 2, 'reg_alpha': 2.4183047465313974e-06, 'n_feat': 14}\n",
      "0.7773953766969526\n",
      "0.7723547743246885\n",
      "0.7876126332976172\n",
      "0.7886081817364952\n",
      "0.7769274104494825\n",
      "0.7805796753010472\n",
      "0.006403861428583037\n",
      "\n",
      " \t ::: 5 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 264, 'learning_rate': 0.23594866607012313, 'max_depth': 22, 'min_child_weight': 15, 'reg_alpha': 2.666527150769371e-06, 'n_feat': 12}\n",
      "0.7750369390770537\n",
      "0.7612934595384453\n",
      "0.7698851982243993\n",
      "0.7834001462191327\n",
      "0.7686535937573353\n",
      "0.7716538673632732\n",
      "0.0073333228990716225\n",
      "\n",
      " \t ::: 6 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 367, 'learning_rate': 0.14995139434241234, 'max_depth': 10, 'min_child_weight': 25, 'reg_alpha': 0.000981804763380463, 'n_feat': 15}\n",
      "0.7791303398395089\n",
      "0.7685639270524658\n",
      "0.7829169855604878\n",
      "0.7868570238280005\n",
      "0.7672431565217923\n",
      "0.7769422865604512\n",
      "0.007785327891995675\n",
      "\n",
      " \t ::: 7 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 825, 'learning_rate': 0.22794262846271685, 'max_depth': 6, 'min_child_weight': 14, 'reg_alpha': 0.0003211892784782023, 'n_feat': 8}\n",
      "0.7513642968514029\n",
      "0.7353371252010221\n",
      "0.7477248839226491\n",
      "0.7417282039552683\n",
      "0.7341484000416396\n",
      "0.7420605819943964\n",
      "0.006731439610390741\n",
      "\n",
      " \t ::: 8 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 601, 'learning_rate': 0.08752067527428713, 'max_depth': 7, 'min_child_weight': 5, 'reg_alpha': 1.7347162057806778e-05, 'n_feat': 10}\n",
      "0.7749369382607205\n",
      "0.759343443619948\n",
      "0.7773498647890199\n",
      "0.7781584149519274\n",
      "0.7693924914118456\n",
      "0.7718362306066923\n",
      "0.006957386760789055\n",
      "\n",
      " \t ::: 9 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 575, 'learning_rate': 0.9168577081509358, 'max_depth': 6, 'min_child_weight': 14, 'reg_alpha': 4.450855136583523e-06, 'n_feat': 18}\n",
      "0.7436606625360207\n",
      "0.7407606388623582\n",
      "0.7513791519975508\n",
      "0.7477237499897892\n",
      "0.7419473933446141\n",
      "0.7450943193460666\n",
      "0.0039281631485922975\n",
      "\n",
      " \t ::: 10 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 654, 'learning_rate': 0.09704623248505599, 'max_depth': 12, 'min_child_weight': 1, 'reg_alpha': 0.008142918699695441, 'n_feat': 8}\n",
      "0.7635878660233962\n",
      "0.745657617613205\n",
      "0.7646247257513139\n",
      "0.7615938906542284\n",
      "0.7518661248083868\n",
      "0.7574660449701062\n",
      "0.0074372115203012465\n",
      "\n",
      " \t ::: 11 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 551, 'learning_rate': 0.08630890734385743, 'max_depth': 22, 'min_child_weight': 9, 'reg_alpha': 9.850156781318652e-05, 'n_feat': 10}\n",
      "0.7716241561155601\n",
      "0.758786296214663\n",
      "0.7741721516403899\n",
      "0.7747934348426306\n",
      "0.7668094113516725\n",
      "0.7692370900329832\n",
      "0.005933609363750116\n",
      "\n",
      " \t ::: 12 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 27}\n",
      "0.711523410395187\n",
      "0.7110614168278926\n",
      "0.724652278177458\n",
      "0.7303415932167392\n",
      "0.7134383438895002\n",
      "0.7182034085013553\n",
      "0.00783912889039992\n",
      "\n",
      " \t ::: 13 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 7}\n",
      "0.711523410395187\n",
      "0.7110614168278926\n",
      "0.724652278177458\n",
      "0.7308273736103055\n",
      "0.7134383438895002\n",
      "0.7183005645800687\n",
      "0.007990512864273117\n",
      "\n",
      " \t ::: 14 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.12318120928579415, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 27}\n",
      "0.7752672981003926\n",
      "0.7649636425603474\n",
      "0.776749834175213\n",
      "0.7780152080150957\n",
      "0.7696078331315994\n",
      "0.7729207631965297\n",
      "0.004907395501854986\n",
      "\n",
      " \t ::: 15 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.08841967040061964, 'max_depth': 24, 'min_child_weight': 3, 'reg_alpha': 1e-06, 'n_feat': 22}\n",
      "0.7797487122343855\n",
      "0.7737456020049144\n",
      "0.7981789887239145\n",
      "0.7914942737646934\n",
      "0.780414721617247\n",
      "0.7847164596690309\n",
      "0.00883992799965974\n",
      "\n",
      " \t ::: 16 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.08761492956992842, 'max_depth': 25, 'min_child_weight': 23, 'reg_alpha': 0.01, 'n_feat': 17}\n",
      "0.7858038637050099\n",
      "0.7807410672740187\n",
      "0.7983121587836114\n",
      "0.7967661269900914\n",
      "0.7914032727859095\n",
      "0.790605297907728\n",
      "0.006608253927423885\n",
      "\n",
      " \t ::: 17 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 103, 'learning_rate': 0.06396494549254302, 'max_depth': 25, 'min_child_weight': 20, 'reg_alpha': 1.4511338648601591e-05, 'n_feat': 21}\n",
      "0.7873819378117373\n",
      "0.7821446501604095\n",
      "0.8012041430685239\n",
      "0.7973634607373039\n",
      "0.7915548284512338\n",
      "0.7919298040458418\n",
      "0.006813382711836568\n",
      "\n",
      " \t ::: 18 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 101, 'learning_rate': 0.9719579884770502, 'max_depth': 21, 'min_child_weight': 12, 'reg_alpha': 8.2957887153288e-06, 'n_feat': 7}\n",
      "0.7157943636274582\n",
      "0.7016439930121878\n",
      "0.7351716924332874\n",
      "0.7198338799532752\n",
      "0.7128885081003187\n",
      "0.7170664874253054\n",
      "0.010884705360317548\n",
      "\n",
      " \t ::: 19 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 1.0, 'max_depth': 6, 'min_child_weight': 20, 'reg_alpha': 3.7071769975917475e-06, 'n_feat': 27}\n",
      "0.7333195066898506\n",
      "0.7182487203977176\n",
      "0.7336996785550283\n",
      "0.7140318292095181\n",
      "0.712431034517951\n",
      "0.7223461538740132\n",
      "0.009311751094907155\n",
      "\n",
      " \t ::: 20 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 18, 'min_child_weight': 24, 'reg_alpha': 1.353208715690236e-06, 'n_feat': 25}\n",
      "0.7829926162662552\n",
      "0.7800803475946743\n",
      "0.7971238328486147\n",
      "0.7992744181867194\n",
      "0.7912246718335072\n",
      "0.7901391773459541\n",
      "0.007558699983770238\n",
      "\n",
      " \t ::: 21 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.03476719986452415, 'max_depth': 2, 'min_child_weight': 25, 'reg_alpha': 1e-06, 'n_feat': 25}\n",
      "0.7842380345962007\n",
      "0.7740568290353391\n",
      "0.7822424613500689\n",
      "0.7858640202909679\n",
      "0.7786292223816591\n",
      "0.7810061135308471\n",
      "0.004231200641127622\n",
      "\n",
      " \t ::: 22 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 19, 'min_child_weight': 25, 'reg_alpha': 1e-06, 'n_feat': 14}\n",
      "0.788066127070425\n",
      "0.7819380158205373\n",
      "0.8017954997703964\n",
      "0.801041913428471\n",
      "0.794008805537242\n",
      "0.7933700723254145\n",
      "0.007603639981689331\n",
      "\n",
      " \t ::: 23 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 18, 'reg_alpha': 0.01, 'n_feat': 5}\n",
      "0.761047539163585\n",
      "0.7421887117445857\n",
      "0.7623082810347467\n",
      "0.7555837941822756\n",
      "0.7558060618183823\n",
      "0.755386877588715\n",
      "0.007132390740001737\n",
      "\n",
      " \t ::: 24 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 742, 'learning_rate': 0.018433648721319872, 'max_depth': 25, 'min_child_weight': 14, 'reg_alpha': 1e-06, 'n_feat': 27}\n",
      "0.7843655866578503\n",
      "0.7779231871280582\n",
      "0.7985820705138016\n",
      "0.7935129555052729\n",
      "0.7897341193136007\n",
      "0.7888235838237166\n",
      "0.007165748125356898\n",
      "\n",
      " \t ::: 25 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.04295125612912742, 'max_depth': 18, 'min_child_weight': 20, 'reg_alpha': 0.01, 'n_feat': 25}\n",
      "0.7841660952334304\n",
      "0.7757805675964702\n",
      "0.7987580999030564\n",
      "0.7981660322335586\n",
      "0.789799946521772\n",
      "0.7893341482976576\n",
      "0.008688363804560452\n",
      "\n",
      " \t ::: 26 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 389, 'learning_rate': 0.03923918748319476, 'max_depth': 17, 'min_child_weight': 25, 'reg_alpha': 1e-06, 'n_feat': 26}\n",
      "0.7820997518347089\n",
      "0.7765645025673679\n",
      "0.794421399050972\n",
      "0.7937212565043008\n",
      "0.7851915316613561\n",
      "0.7863996883237411\n",
      "0.006850301873741008\n",
      "\n",
      " \t ::: 27 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.01748846511821888, 'max_depth': 25, 'min_child_weight': 25, 'reg_alpha': 0.01, 'n_feat': 21}\n",
      "0.786017385856211\n",
      "0.7785201307765777\n",
      "0.7938277463135874\n",
      "0.7955985182038737\n",
      "0.787742463550097\n",
      "0.7883412489400693\n",
      "0.006082480680676446\n",
      "\n",
      " \t ::: 28 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.02076760108788492, 'max_depth': 25, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 19}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784343137495\n",
      "0.7785782945166899\n",
      "0.7991912852696565\n",
      "0.7980884299005873\n",
      "0.7883257232317996\n",
      "0.7897053740827465\n",
      "0.007933814382172288\n",
      "\n",
      " \t ::: 29 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 502, 'learning_rate': 0.036813463532164116, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 0.01, 'n_feat': 20}\n",
      "0.779763508273537\n",
      "0.769836386419481\n",
      "0.7792943517526405\n",
      "0.7825046561399782\n",
      "0.7726907407142815\n",
      "0.7768179286599837\n",
      "0.004752338212299759\n",
      "\n",
      " \t ::: 30 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 480, 'learning_rate': 0.06026834213066721, 'max_depth': 25, 'min_child_weight': 25, 'reg_alpha': 0.01, 'n_feat': 27}\n",
      "0.779114268279741\n",
      "0.7771333847623245\n",
      "0.7887463646104393\n",
      "0.789619564773442\n",
      "0.7815633808854117\n",
      "0.7832353926622717\n",
      "0.005062455043312501\n",
      "\n",
      " \t ::: 31 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 798, 'learning_rate': 0.020792518125877926, 'max_depth': 25, 'min_child_weight': 25, 'reg_alpha': 1e-06, 'n_feat': 18}\n",
      "0.7844895672617735\n",
      "0.7806752504102075\n",
      "0.7961416398795857\n",
      "0.7995245836022185\n",
      "0.7893932466387301\n",
      "0.7900448575585031\n",
      "0.007015858403925476\n",
      "\n",
      " \t ::: 32 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.08712361467549573, 'max_depth': 2, 'min_child_weight': 25, 'reg_alpha': 1e-06, 'n_feat': 9}\n",
      "0.766084570078123\n",
      "0.7544638119494853\n",
      "0.7691249553548651\n",
      "0.7685398099968141\n",
      "0.7615205268626039\n",
      "0.7639467348483783\n",
      "0.005445970222083522\n",
      "\n",
      " \t ::: 33 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.057912959363163236, 'max_depth': 25, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 27}\n",
      "0.786776830831272\n",
      "0.7724450811843362\n",
      "0.7938338690749529\n",
      "0.7954152337463957\n",
      "0.7833396949291618\n",
      "0.7863621419532238\n",
      "0.008255627299253847\n",
      "\n",
      " \t ::: 34 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 25, 'min_child_weight': 1, 'reg_alpha': 3.483697058954075e-05, 'n_feat': 27}\n",
      "0.7826298582029241\n",
      "0.7703578192475041\n",
      "0.7963753252716975\n",
      "0.7950410067064753\n",
      "0.7810071664907873\n",
      "0.7850822351838775\n",
      "0.009655462457576678\n",
      "\n",
      " \t ::: 35 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 1.0, 'max_depth': 25, 'min_child_weight': 1, 'reg_alpha': 3.8789034953905685e-06, 'n_feat': 27}\n",
      "0.7569130666372788\n",
      "0.7537936534175789\n",
      "0.7647918261135772\n",
      "0.7631278130845701\n",
      "0.7618412431442748\n",
      "0.760093520479456\n",
      "0.004102173901670458\n",
      "\n",
      " \t ::: 36 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 655, 'learning_rate': 0.012708028379729439, 'max_depth': 21, 'min_child_weight': 25, 'reg_alpha': 1.731748779769932e-06, 'n_feat': 19}\n",
      "0.7868814235218247\n",
      "0.7840092061976016\n",
      "0.8016873309862749\n",
      "0.8000182773915814\n",
      "0.7940037026528876\n",
      "0.793319988150034\n",
      "0.006978434573189063\n",
      "\n",
      " \t ::: 37 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 25, 'min_child_weight': 13, 'reg_alpha': 0.00022748508211035845, 'n_feat': 19}\n",
      "0.7878482681491277\n",
      "0.7839875223471211\n",
      "0.8018235624266544\n",
      "0.796743663156863\n",
      "0.7923631253329633\n",
      "0.7925532282825459\n",
      "0.006309404833104046\n",
      "\n",
      " \t ::: 38 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 227, 'learning_rate': 0.015861111893800503, 'max_depth': 23, 'min_child_weight': 25, 'reg_alpha': 1.0642210717353241e-06, 'n_feat': 17}\n",
      "0.7866462175201431\n",
      "0.7808395374656119\n",
      "0.801878157048829\n",
      "0.7980848561089374\n",
      "0.7917048532512517\n",
      "0.7918307242789545\n",
      "0.007586385326695814\n",
      "\n",
      " \t ::: 39 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 25, 'min_child_weight': 2, 'reg_alpha': 1.7473300249527843e-05, 'n_feat': 5}\n",
      "0.7326289398280803\n",
      "0.7219620160164573\n",
      "0.7369756110005612\n",
      "0.7328315049134528\n",
      "0.7285454330205605\n",
      "0.7305887009558225\n",
      "0.005071094577429193\n",
      "\n",
      " \t ::: 40 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 250, 'learning_rate': 0.034591731302067344, 'max_depth': 22, 'min_child_weight': 24, 'reg_alpha': 1.356787126198538e-06, 'n_feat': 18}\n",
      "0.7890982783532927\n",
      "0.7833665989110115\n",
      "0.8018705035971223\n",
      "0.8008953879708216\n",
      "0.7951615471128901\n",
      "0.7940784631890276\n",
      "0.007041387722556817\n",
      "\n",
      " \t ::: 41 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 996, 'learning_rate': 0.010331381142877563, 'max_depth': 3, 'min_child_weight': 23, 'reg_alpha': 0.0003427087369177924, 'n_feat': 22}\n",
      "0.7831665972783451\n",
      "0.7740558086188459\n",
      "0.790165824786979\n",
      "0.7916984904304071\n",
      "0.7839551027822966\n",
      "0.7846083647793748\n",
      "0.006245272288195515\n",
      "\n",
      " \t ::: 42 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 962, 'learning_rate': 0.20608531950556022, 'max_depth': 3, 'min_child_weight': 2, 'reg_alpha': 2.6270493308748425e-05, 'n_feat': 24}\n",
      "0.7680639229707997\n",
      "0.7547816716871159\n",
      "0.7716674320118373\n",
      "0.7630606768557169\n",
      "0.7546191309175598\n",
      "0.7624385668886059\n",
      "0.006884405949061128\n",
      "\n",
      " \t ::: 43 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 202, 'learning_rate': 0.05497687894559106, 'max_depth': 2, 'min_child_weight': 25, 'reg_alpha': 1.577208319674964e-06, 'n_feat': 20}\n",
      "0.7739017257283732\n",
      "0.7614102972269161\n",
      "0.7742616970253584\n",
      "0.7759607883580164\n",
      "0.7686597172185605\n",
      "0.770838845111445\n",
      "0.005309944803924709\n",
      "\n",
      " \t ::: 44 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'learning_rate': 0.017117319164478548, 'max_depth': 11, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 17}\n",
      "0.7829931264745018\n",
      "0.7761772545082001\n",
      "0.7972922087861626\n",
      "0.7961330553263791\n",
      "0.7846950210136778\n",
      "0.7874581332217844\n",
      "0.008084461820123252\n",
      "\n",
      " \t ::: 45 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 243, 'learning_rate': 0.011312602317154431, 'max_depth': 25, 'min_child_weight': 24, 'reg_alpha': 2.7764891668488616e-06, 'n_feat': 22}\n",
      "0.7858110066204621\n",
      "0.7767032792104426\n",
      "0.7988795346701362\n",
      "0.7946407420416767\n",
      "0.786605030627512\n",
      "0.7885279186340459\n",
      "0.007686660799657832\n",
      "\n",
      " \t ::: 46 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 443, 'learning_rate': 0.03948177409472418, 'max_depth': 22, 'min_child_weight': 1, 'reg_alpha': 0.0020767861550932487, 'n_feat': 20}\n",
      "0.7868707091486462\n",
      "0.7759667936064785\n",
      "0.8010844941068422\n",
      "0.7971076793634976\n",
      "0.7886176082168685\n",
      "0.7899294568884665\n",
      "0.008740647388421468\n",
      "\n",
      " \t ::: 47 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 989, 'learning_rate': 0.021467222063924582, 'max_depth': 11, 'min_child_weight': 23, 'reg_alpha': 6.5646580322748235e-06, 'n_feat': 17}\n",
      "0.7844201789402363\n",
      "0.7811349480403922\n",
      "0.7970472983315475\n",
      "0.7975988204445389\n",
      "0.7882507108317907\n",
      "0.7896903913177011\n",
      "0.006628887691625857\n",
      "\n",
      " \t ::: 48 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 218, 'learning_rate': 0.024906370908638616, 'max_depth': 25, 'min_child_weight': 25, 'reg_alpha': 8.733924314446965e-06, 'n_feat': 22}\n",
      "0.7884615384615385\n",
      "0.7801936138254191\n",
      "0.8011964896168171\n",
      "0.8026261242127448\n",
      "0.7922595367805698\n",
      "0.7929474605794178\n",
      "0.008306387340018855\n",
      "\n",
      " \t ::: 49 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 943, 'learning_rate': 0.030721928970871334, 'max_depth': 14, 'min_child_weight': 4, 'reg_alpha': 0.0012389706184763826, 'n_feat': 26}\n",
      "0.783564049502445\n",
      "0.7746119356076377\n",
      "0.7946925863564467\n",
      "0.7942175030019851\n",
      "0.7838882549972548\n",
      "0.7861948658931539\n",
      "0.007523029734862031\n",
      "\n",
      " \t ::: 50 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 131, 'learning_rate': 0.25805782053177767, 'max_depth': 25, 'min_child_weight': 6, 'reg_alpha': 1.0082942460492188e-06, 'n_feat': 26}\n",
      "0.7669067706675158\n",
      "0.7622148956318011\n",
      "0.7820268891269962\n",
      "0.781688300018788\n",
      "0.777699476852296\n",
      "0.7741072664594795\n",
      "0.008079258531357547\n"
     ]
    }
   ],
   "source": [
    "search_result = optimize('xgboost', skopt_dims, init_param, X_train, cv = True, num_calls=50, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>n_feat</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>250</td>\n",
       "      <td>0.034592</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.794078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.793370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>655</td>\n",
       "      <td>0.012708</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.793320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>218</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.792947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.792553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>103</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.791930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>227</td>\n",
       "      <td>0.015861</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.791831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.087615</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.790605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.790139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>798</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.790045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>443</td>\n",
       "      <td>0.039482</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.789929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020768</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.789705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>989</td>\n",
       "      <td>0.021467</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.789690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>0.042951</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.789334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>742</td>\n",
       "      <td>0.018434</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.788824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>243</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.788528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.788341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.787458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>389</td>\n",
       "      <td>0.039239</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.786400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.057913</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.786362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>943</td>\n",
       "      <td>0.030722</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.786195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.785082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.088420</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.784716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>996</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.784608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>480</td>\n",
       "      <td>0.060268</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.783235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.034767</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.781006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>613</td>\n",
       "      <td>0.108934</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.780580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>367</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.776942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>502</td>\n",
       "      <td>0.036813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.776818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>131</td>\n",
       "      <td>0.258058</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.774107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.773358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>0.123181</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.772921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>601</td>\n",
       "      <td>0.087521</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.771836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>620</td>\n",
       "      <td>0.194393</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.771712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>264</td>\n",
       "      <td>0.235949</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.771654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>202</td>\n",
       "      <td>0.054977</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.770839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>551</td>\n",
       "      <td>0.086309</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.769237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>0.087124</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.763947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>962</td>\n",
       "      <td>0.206085</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.762439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.760094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>654</td>\n",
       "      <td>0.097046</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.757466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.755387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>871</td>\n",
       "      <td>0.552495</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.753955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>575</td>\n",
       "      <td>0.916858</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.745094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>825</td>\n",
       "      <td>0.227943</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.742061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.730589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.722346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.718301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.718203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>101</td>\n",
       "      <td>0.971958</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.717066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    call  n_estimators  learning_rate  max_depth  min_child_weight  reg_alpha  \\\n",
       "39    39           250       0.034592         22                24   0.000001   \n",
       "21    21          1000       0.010000         19                25   0.000001   \n",
       "35    35           655       0.012708         21                25   0.000002   \n",
       "47    47           218       0.024906         25                25   0.000009   \n",
       "36    36          1000       0.010000         25                13   0.000227   \n",
       "16    16           103       0.063965         25                20   0.000015   \n",
       "37    37           227       0.015861         23                25   0.000001   \n",
       "15    15           100       0.087615         25                23   0.010000   \n",
       "19    19          1000       0.010000         18                24   0.000001   \n",
       "30    30           798       0.020793         25                25   0.000001   \n",
       "45    45           443       0.039482         22                 1   0.002077   \n",
       "27    27          1000       0.020768         25                 1   0.000001   \n",
       "46    46           989       0.021467         11                23   0.000007   \n",
       "24    24           100       0.042951         18                20   0.010000   \n",
       "23    23           742       0.018434         25                14   0.000001   \n",
       "44    44           243       0.011313         25                24   0.000003   \n",
       "26    26          1000       0.017488         25                25   0.010000   \n",
       "43    43          1000       0.017117         11                 1   0.000001   \n",
       "25    25           389       0.039239         17                25   0.000001   \n",
       "32    32          1000       0.057913         25                 1   0.000001   \n",
       "48    48           943       0.030722         14                 4   0.001239   \n",
       "33    33          1000       0.010000         25                 1   0.000035   \n",
       "14    14           100       0.088420         24                 3   0.000001   \n",
       "40    40           996       0.010331          3                23   0.000343   \n",
       "29    29           480       0.060268         25                25   0.010000   \n",
       "20    20          1000       0.034767          2                25   0.000001   \n",
       "3      3           613       0.108934         10                 2   0.000002   \n",
       "5      5           367       0.149951         10                25   0.000982   \n",
       "28    28           502       0.036813          2                 1   0.010000   \n",
       "49    49           131       0.258058         25                 6   0.000001   \n",
       "0      0           100       0.300000          6                 1   0.000010   \n",
       "13    13           100       0.123181          2                 1   0.000001   \n",
       "7      7           601       0.087521          7                 5   0.000017   \n",
       "2      2           620       0.194393          8                14   0.000251   \n",
       "4      4           264       0.235949         22                15   0.000003   \n",
       "42    42           202       0.054977          2                25   0.000002   \n",
       "10    10           551       0.086309         22                 9   0.000099   \n",
       "31    31           100       0.087124          2                25   0.000001   \n",
       "41    41           962       0.206085          3                 2   0.000026   \n",
       "34    34          1000       1.000000         25                 1   0.000004   \n",
       "9      9           654       0.097046         12                 1   0.008143   \n",
       "22    22          1000       0.010000          9                18   0.010000   \n",
       "1      1           871       0.552495         22                24   0.000086   \n",
       "8      8           575       0.916858          6                14   0.000004   \n",
       "6      6           825       0.227943          6                14   0.000321   \n",
       "38    38           100       0.010000         25                 2   0.000017   \n",
       "18    18           100       1.000000          6                20   0.000004   \n",
       "12    12           100       0.010000          2                 1   0.000001   \n",
       "11    11           100       0.010000          2                 1   0.000001   \n",
       "17    17           101       0.971958         21                12   0.000008   \n",
       "\n",
       "    n_feat     score  \n",
       "39      18 -0.794078  \n",
       "21      14 -0.793370  \n",
       "35      19 -0.793320  \n",
       "47      22 -0.792947  \n",
       "36      19 -0.792553  \n",
       "16      21 -0.791930  \n",
       "37      17 -0.791831  \n",
       "15      17 -0.790605  \n",
       "19      25 -0.790139  \n",
       "30      18 -0.790045  \n",
       "45      20 -0.789929  \n",
       "27      19 -0.789705  \n",
       "46      17 -0.789690  \n",
       "24      25 -0.789334  \n",
       "23      27 -0.788824  \n",
       "44      22 -0.788528  \n",
       "26      21 -0.788341  \n",
       "43      17 -0.787458  \n",
       "25      26 -0.786400  \n",
       "32      27 -0.786362  \n",
       "48      26 -0.786195  \n",
       "33      27 -0.785082  \n",
       "14      22 -0.784716  \n",
       "40      22 -0.784608  \n",
       "29      27 -0.783235  \n",
       "20      25 -0.781006  \n",
       "3       14 -0.780580  \n",
       "5       15 -0.776942  \n",
       "28      20 -0.776818  \n",
       "49      26 -0.774107  \n",
       "0       12 -0.773358  \n",
       "13      27 -0.772921  \n",
       "7       10 -0.771836  \n",
       "2       19 -0.771712  \n",
       "4       12 -0.771654  \n",
       "42      20 -0.770839  \n",
       "10      10 -0.769237  \n",
       "31       9 -0.763947  \n",
       "41      24 -0.762439  \n",
       "34      27 -0.760094  \n",
       "9        8 -0.757466  \n",
       "22       5 -0.755387  \n",
       "1       21 -0.753955  \n",
       "8       18 -0.745094  \n",
       "6        8 -0.742061  \n",
       "38       5 -0.730589  \n",
       "18      27 -0.722346  \n",
       "12       7 -0.718301  \n",
       "11      27 -0.718203  \n",
       "17       7 -0.717066  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZuH8bAbIxAy"
   },
   "outputs": [],
   "source": [
    "#search_result.to_hdf('xgboost.h5', 'frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaC2QkDngdWI"
   },
   "source": [
    "### 2. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMJ02LakiRc8"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Reshape\n",
    "\n",
    "def create_model( n_features, dense_layers, dense_units, regulizer_value, dropout_value, learning_rate ):\n",
    "\n",
    "    m_input = Input(shape = (n_features, ))\n",
    "    m = m_input\n",
    "    \n",
    "    for _ in range(dense_layers):\n",
    "        m = Dense( units=dense_units, activation='relu', \n",
    "                   kernel_initializer='lecun_normal',\n",
    "                   kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
    "        m = Dropout(dropout_value)(m)\n",
    "\n",
    "    m_output = Dense( units=1, activation='sigmoid', \n",
    "                      kernel_initializer='lecun_normal',\n",
    "                      kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
    "\n",
    "    model = keras.models.Model(inputs=m_input, outputs=m_output)\n",
    "    model.compile( loss = 'binary_crossentropy',\n",
    "                        optimizer = keras.optimizers.Adam(lr=learning_rate) )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqB7c3v4ipkw"
   },
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    Integer(        low=20,    high=200,                         name='epochs'     ),\n",
    "    Integer(     low=1,    high=5,                        name='dense_layers'      ),\n",
    "    Integer(     low=100,    high=1000,                    name='batch_size'      ),\n",
    "    Integer(     low=5,    high=200,                        name='dense_units'       ),\n",
    "    #Real(        low=1e-3, high=0.9,  prior=\"log-uniform\", name='regulizer_value'   ),\n",
    "    Real(        low=1e-3, high=0.5,   prior=\"log-uniform\",                    name='dropout_value'     ),\n",
    "    Real(        low=1e-4, high=1e-1, prior='log-uniform', name='learning_rate'     ),\n",
    "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# Initial parameters\n",
    "init_param = {'epochs' : 50 ,'learning_rate' : 1e-2, 'dense_layers' : 3, 'regulizer_value' : 1e-2, 'dropout_value': 0.02, \n",
    "             'dense_units' : 20, 'batch_size' : 100, 'n_feat': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "f7oIVki7gT9T",
    "outputId": "af6386f1-084b-4855-edf3-22b56e4f38e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0227 22:26:58.030966 139739968608064 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0227 22:26:58.075168 139739968608064 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0227 22:26:58.083770 139739968608064 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0227 22:26:58.119535 139739968608064 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0227 22:26:58.135347 139739968608064 deprecation.py:506] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs\n",
      "dense_layers\n",
      "batch_size\n",
      "dense_units\n",
      "dropout_value\n",
      "learning_rate\n",
      "n_feat\n",
      "\n",
      " \t ::: 1 SKOPT CALL ::: \n",
      "\n",
      "{'epochs': 50, 'dense_layers': 3, 'batch_size': 100, 'dense_units': 20, 'dropout_value': 0.02, 'learning_rate': 0.01, 'n_feat': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0227 22:26:58.321961 139739968608064 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0227 22:26:58.332959 139739968608064 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0227 22:26:58.341514 139739968608064 deprecation.py:323] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727082465979314\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-ae0273ac36e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_result_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-124-71f1355c4d4d>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(algo, dimensions, initial_param, data, cv, kfold_splits, num_calls, random_state)\u001b[0m\n\u001b[1;32m    137\u001b[0m     search_result = gp_minimize( func = fitness, dimensions = dimensions,\n\u001b[1;32m    138\u001b[0m                                  \u001b[0macq_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                                  n_calls = num_calls, x0 = prior_values )\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# evaluate y0 if only x0 is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mn_calls\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# record through tell function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-71f1355c4d4d>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(**p)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfit_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'keras'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfit_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_rf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-71f1355c4d4d>\u001b[0m in \u001b[0;36mfit_keras\u001b[0;34m(X_train, y_train, X_test, y_test, p)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#                    epochs=1000, verbose=0, callbacks=[es])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_result_k = optimize('keras', dimensions, init_param, X_train, cv = True, num_calls=12, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    Real(        low=1e-3, high=100,   prior=\"log-uniform\",                    name='C'     ),\n",
    "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
    "]\n",
    "\n",
    "# Initial parameters\n",
    "init_param = {'C' : 0.1, 'n_feat': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "n_feat\n",
      "\n",
      " \t ::: 1 SKOPT CALL ::: \n",
      "\n",
      "{'C': 0.1, 'n_feat': 20}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'y_pred' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-8be4f2b6bc9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_result_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lreg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-124-71f1355c4d4d>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(algo, dimensions, initial_param, data, cv, kfold_splits, num_calls, random_state)\u001b[0m\n\u001b[1;32m    137\u001b[0m     search_result = gp_minimize( func = fitness, dimensions = dimensions,\n\u001b[1;32m    138\u001b[0m                                  \u001b[0macq_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                                  n_calls = num_calls, x0 = prior_values )\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# evaluate y0 if only x0 is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mn_calls\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# record through tell function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-71f1355c4d4d>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(**p)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_rf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'y_pred' referenced before assignment"
     ]
    }
   ],
   "source": [
    "search_result_k = optimize('lreg', dimensions, init_param, X_train, cv = True, num_calls=12, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>C</th>\n",
       "      <th>n_feat</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>98.971806</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.685734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>13.799586</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.685698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>16.849722</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.685674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>97.217833</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.685657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>99.704363</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.685657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    call          C  n_feat     score\n",
       "46    46  98.971806      19 -0.685734\n",
       "48    48  13.799586      19 -0.685698\n",
       "9      9  16.849722      24 -0.685674\n",
       "34    34  97.217833      27 -0.685657\n",
       "44    44  99.704363      27 -0.685657"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    Integer(     low=100,    high=1000,                        name='n_estimators'       ),\n",
    "    Integer(     low=5,    high=30,                        name='max_depth'       ),\n",
    "    Integer(     low=2,    high=100,                        name='min_samples_split'       ),\n",
    "    Integer(     low=1,    high=10,                        name='min_samples_leaf'       ),\n",
    "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
    "]\n",
    "\n",
    "# Initial parameters\n",
    "init_param = {'n_estimators': 200, 'max_depth': 10, 'min_samples_split' : 20, 'min_samples_leaf' : 4, 'n_feat': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators\n",
      "max_depth\n",
      "min_samples_split\n",
      "min_samples_leaf\n",
      "n_feat\n",
      "\n",
      " \t ::: 1 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 4, 'n_feat': 20}\n",
      "0.7790976865117267\n",
      "0.775976742667287\n",
      "0.7933420072452676\n",
      "0.7910026221419877\n",
      "0.7812485329207481\n",
      "0.7841335182974035\n",
      "0.00681463993777847\n",
      "\n",
      " \t ::: 2 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 572, 'max_depth': 13, 'min_samples_split': 87, 'min_samples_leaf': 6, 'n_feat': 18}\n",
      "0.7804114727467162\n",
      "0.7756298010596006\n",
      "0.7950635236491657\n",
      "0.7942231189602921\n",
      "0.7818266897180963\n",
      "0.7854309212267742\n",
      "0.0078017571707483906\n",
      "\n",
      " \t ::: 3 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 788, 'max_depth': 17, 'min_samples_split': 97, 'min_samples_leaf': 3, 'n_feat': 22}\n",
      "0.7796349357953943\n",
      "0.7739690732169243\n",
      "0.7924388999438747\n",
      "0.7922636600527695\n",
      "0.7809836932227573\n",
      "0.7838580524463441\n",
      "0.007323574924894503\n",
      "\n",
      " \t ::: 4 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 181, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 5, 'n_feat': 5}\n",
      "0.7539551343276272\n",
      "0.7396070580168002\n",
      "0.7601520485739068\n",
      "0.7583805414192242\n",
      "0.7547824232168991\n",
      "0.7533754411108916\n",
      "0.007250620024550761\n",
      "\n",
      " \t ::: 5 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 915, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 10, 'n_feat': 15}\n",
      "0.7858727418183007\n",
      "0.7813431130050041\n",
      "0.7978983621613347\n",
      "0.7962213790343002\n",
      "0.7898320946932045\n",
      "0.7902335381424288\n",
      "0.006210010085897946\n",
      "\n",
      " \t ::: 6 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 820, 'max_depth': 21, 'min_samples_split': 71, 'min_samples_leaf': 7, 'n_feat': 24}\n",
      "0.7785936007640879\n",
      "0.773847643654234\n",
      "0.7924598193785397\n",
      "0.7905390503108178\n",
      "0.7811316768690335\n",
      "0.7833143581953427\n",
      "0.007106391054770031\n",
      "\n",
      " \t ::: 7 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 862, 'max_depth': 30, 'min_samples_split': 95, 'min_samples_leaf': 3, 'n_feat': 26}\n",
      "0.7788303373905093\n",
      "0.7730726373276516\n",
      "0.7918159089749476\n",
      "0.7905599825190535\n",
      "0.7788221114102534\n",
      "0.782620195524483\n",
      "0.0073149941697652375\n",
      "\n",
      " \t ::: 8 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 353, 'max_depth': 22, 'min_samples_split': 87, 'min_samples_leaf': 5, 'n_feat': 13}\n",
      "0.7827293488110107\n",
      "0.7775747148956318\n",
      "0.7958946885045155\n",
      "0.7940510664194285\n",
      "0.7836591354897442\n",
      "0.7867817908240662\n",
      "0.007026105344695175\n",
      "\n",
      " \t ::: 9 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 301, 'max_depth': 13, 'min_samples_split': 72, 'min_samples_leaf': 6, 'n_feat': 20}\n",
      "0.781261989893795\n",
      "0.7763190924007544\n",
      "0.7931450584213481\n",
      "0.793297506922945\n",
      "0.7818481218323845\n",
      "0.7851743538942454\n",
      "0.0068454921474722765\n",
      "\n",
      " \t ::: 10 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 502, 'max_depth': 11, 'min_samples_split': 30, 'min_samples_leaf': 7, 'n_feat': 7}\n",
      "0.7724486526420624\n",
      "0.7675378982685573\n",
      "0.7814133374151742\n",
      "0.7804405361912775\n",
      "0.7758466195432305\n",
      "0.7755374088120603\n",
      "0.005141894396723971\n",
      "\n",
      " \t ::: 11 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 521, 'max_depth': 9, 'min_samples_split': 95, 'min_samples_leaf': 7, 'n_feat': 25}\n",
      "0.7744053012677654\n",
      "0.7694465873190802\n",
      "0.7865651308740242\n",
      "0.7872246138262851\n",
      "0.7755287098479544\n",
      "0.7786340686270219\n",
      "0.0070517338931022\n",
      "\n",
      " \t ::: 12 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 997, 'max_depth': 17, 'min_samples_split': 22, 'min_samples_leaf': 1, 'n_feat': 13}\n",
      "0.789224809998449\n",
      "0.7825528167576878\n",
      "0.7998908107556507\n",
      "0.7993019874365908\n",
      "0.7904332144701471\n",
      "0.7922807278837051\n",
      "0.006551269218056347\n",
      "\n",
      " \t ::: 13 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 2, 'n_feat': 27}\n",
      "0.7519520567514837\n",
      "0.7468841582380263\n",
      "0.7619771416909026\n",
      "0.7683708207059362\n",
      "0.75185234702063\n",
      "0.7562073048813958\n",
      "0.007813270659232562\n",
      "\n",
      " \t ::: 14 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 100, 'min_samples_leaf': 10, 'n_feat': 27}\n",
      "0.7739292769736896\n",
      "0.7690741352990638\n",
      "0.7889448441247002\n",
      "0.7882579501547962\n",
      "0.7768054515134134\n",
      "0.7794023316131325\n",
      "0.007910136246986787\n",
      "\n",
      " \t ::: 15 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 100, 'min_samples_leaf': 7, 'n_feat': 5}\n",
      "0.7436280092082385\n",
      "0.7388371537726838\n",
      "0.7496163069544364\n",
      "0.7515622574927094\n",
      "0.7418435496480029\n",
      "0.7450974554152141\n",
      "0.004778121737404202\n",
      "\n",
      " \t ::: 16 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10, 'n_feat': 11}\n",
      "0.7564725018163414\n",
      "0.7539882978636561\n",
      "0.7682098576457983\n",
      "0.7699540104068812\n",
      "0.7583595451493003\n",
      "0.7613968425763954\n",
      "0.006449854850420081\n",
      "\n",
      " \t ::: 17 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'max_depth': 30, 'min_samples_split': 42, 'min_samples_leaf': 10, 'n_feat': 15}\n",
      "0.7845824251626543\n",
      "0.7797905493106065\n",
      "0.797214143578754\n",
      "0.7960809800766221\n",
      "0.7873245373214757\n",
      "0.7889985270900225\n",
      "0.006704454450015043\n",
      "\n",
      " \t ::: 18 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 647, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'n_feat': 16}\n",
      "0.7855150858374355\n",
      "0.7834395586902749\n",
      "0.7996637583550181\n",
      "0.7994852718940687\n",
      "0.793126771976592\n",
      "0.7922460893506779\n",
      "0.006798008087814703\n",
      "\n",
      " \t ::: 19 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 108, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 10, 'n_feat': 19}\n",
      "0.7844533424762651\n",
      "0.7762696022008344\n",
      "0.7971279146895249\n",
      "0.7934578170055302\n",
      "0.7873750558765837\n",
      "0.7877367464497476\n",
      "0.0072571571315663864\n",
      "\n",
      " \t ::: 20 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 883, 'max_depth': 30, 'min_samples_split': 99, 'min_samples_leaf': 1, 'n_feat': 19}\n",
      "0.7809303545335063\n",
      "0.7749002032669654\n",
      "0.794244094086433\n",
      "0.7926383976343541\n",
      "0.7827462294787506\n",
      "0.7850918558000018\n",
      "0.007313051296051238\n",
      "\n",
      " \t ::: 21 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 592, 'max_depth': 30, 'min_samples_split': 61, 'min_samples_leaf': 1, 'n_feat': 11}\n",
      "0.7866559114768283\n",
      "0.7782604347790594\n",
      "0.7968717791724067\n",
      "0.7950047582483111\n",
      "0.7885058550495081\n",
      "0.7890597477452227\n",
      "0.006619386245958141\n",
      "\n",
      " \t ::: 22 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 3, 'n_feat': 5}\n",
      "0.7513020514453179\n",
      "0.7377947983248844\n",
      "0.7606010510740344\n",
      "0.7546939200614282\n",
      "0.7559392471000308\n",
      "0.7520662136011392\n",
      "0.007733122502604322\n",
      "\n",
      " \t ::: 23 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 22, 'min_samples_leaf': 1, 'n_feat': 16}\n",
      "0.7802931044335056\n",
      "0.7765247063241333\n",
      "0.7951737333537424\n",
      "0.7959155645773941\n",
      "0.7893279297189945\n",
      "0.787447007681554\n",
      "0.007815773945643732\n",
      "\n",
      " \t ::: 24 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 1000, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1, 'n_feat': 19}\n",
      "0.7709425178981053\n",
      "0.766327684307627\n",
      "0.7832578192764937\n",
      "0.7843119736315441\n",
      "0.7706712742310464\n",
      "0.7751022538689634\n",
      "0.0072837111434679086\n",
      "\n",
      " \t ::: 25 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 834, 'max_depth': 30, 'min_samples_split': 98, 'min_samples_leaf': 9, 'n_feat': 19}\n",
      "0.7799777957371081\n",
      "0.7744614241748913\n",
      "0.7938287667738151\n",
      "0.7918302101797923\n",
      "0.7809071499574418\n",
      "0.7842010693646098\n",
      "0.007408683831779804\n",
      "\n",
      " \t ::: 26 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 7, 'n_feat': 27}\n",
      "0.7842747695899558\n",
      "0.7721904872692837\n",
      "0.7909582121536813\n",
      "0.7897150360646632\n",
      "0.7865887013975781\n",
      "0.7847454412950325\n",
      "0.00670136410240002\n",
      "\n",
      " \t ::: 27 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 959, 'max_depth': 18, 'min_samples_split': 49, 'min_samples_leaf': 1, 'n_feat': 15}\n",
      "0.7850217144629752\n",
      "0.7801007559245381\n",
      "0.7981555181386805\n",
      "0.7970785784886334\n",
      "0.7872755496316738\n",
      "0.7895264233293002\n",
      "0.00700996954598413\n",
      "\n",
      " \t ::: 28 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 542, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 6, 'n_feat': 27}\n",
      "0.7848967134425586\n",
      "0.7769318525049184\n",
      "0.794477269248431\n",
      "0.7918889224711851\n",
      "0.7848363709102932\n",
      "0.7866062257154771\n",
      "0.00615643608868461\n",
      "\n",
      " \t ::: 29 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 9, 'n_feat': 27}\n",
      "0.7515449105706986\n",
      "0.7453866970342615\n",
      "0.7614949742333793\n",
      "0.7664021720484565\n",
      "0.751151210710342\n",
      "0.7551959929194275\n",
      "0.007631101722087945\n",
      "\n",
      " \t ::: 30 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 212, 'max_depth': 22, 'min_samples_split': 6, 'min_samples_leaf': 2, 'n_feat': 27}\n",
      "0.7800155511473563\n",
      "0.776348684479057\n",
      "0.7936639624470636\n",
      "0.7924688978018117\n",
      "0.7846174571714916\n",
      "0.7854229106093561\n",
      "0.0067792439455101475\n",
      "\n",
      " \t ::: 31 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 218, 'max_depth': 14, 'min_samples_split': 95, 'min_samples_leaf': 10, 'n_feat': 12}\n",
      "0.7832625164287056\n",
      "0.7747496918342192\n",
      "0.7949053523138936\n",
      "0.7922723392610624\n",
      "0.7838280409618732\n",
      "0.7858035881599508\n",
      "0.007172660702658676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \t ::: 32 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 879, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 3, 'n_feat': 14}\n",
      "0.7892651164499301\n",
      "0.7851217152793084\n",
      "0.8010092351650594\n",
      "0.799821718850832\n",
      "0.7937995872787134\n",
      "0.7938034746047686\n",
      "0.006068144755946828\n",
      "\n",
      " \t ::: 33 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 173, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 3, 'n_feat': 18}\n",
      "0.7834334361913157\n",
      "0.7829734834570079\n",
      "0.799687228940252\n",
      "0.7978487305892058\n",
      "0.7923085244703717\n",
      "0.7912502807296307\n",
      "0.0070064248672362444\n",
      "\n",
      " \t ::: 34 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 997, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 9, 'n_feat': 13}\n",
      "0.7880263308271904\n",
      "0.7833104760038858\n",
      "0.799495892647584\n",
      "0.7978934029848308\n",
      "0.7910771984756664\n",
      "0.7919606601878316\n",
      "0.006050823148116353\n",
      "\n",
      " \t ::: 35 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 272, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'n_feat': 11}\n",
      "0.7900590004816366\n",
      "0.7809329055747394\n",
      "0.7980248992295526\n",
      "0.7971694549048759\n",
      "0.7905536425409099\n",
      "0.7913479805463428\n",
      "0.006152024641489321\n",
      "\n",
      " \t ::: 36 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 293, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 10, 'n_feat': 12}\n",
      "0.7891411358460069\n",
      "0.7809670895272613\n",
      "0.7985376804939028\n",
      "0.7968064597815697\n",
      "0.790146942657868\n",
      "0.7911198616613218\n",
      "0.006249834296360676\n",
      "\n",
      " \t ::: 37 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 514, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'n_feat': 22}\n",
      "0.7859115176450421\n",
      "0.7783599253871459\n",
      "0.799890300525537\n",
      "0.7966578921572632\n",
      "0.7879996489215563\n",
      "0.7897638569273089\n",
      "0.0077210774391392786\n",
      "\n",
      " \t ::: 38 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 136, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'n_feat': 22}\n",
      "0.7793022800186122\n",
      "0.7737619286688054\n",
      "0.7982917495790602\n",
      "0.7946887329581193\n",
      "0.7822793155603274\n",
      "0.7856648013569849\n",
      "0.009321938993970607\n",
      "\n",
      " \t ::: 39 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 907, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 10, 'n_feat': 14}\n",
      "0.7860237634592935\n",
      "0.7817721981403929\n",
      "0.7985836012041431\n",
      "0.7960544319100794\n",
      "0.7900076339149941\n",
      "0.7904883257257806\n",
      "0.006207242287175852\n",
      "\n",
      " \t ::: 40 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 955, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 1, 'n_feat': 27}\n",
      "0.7836563971950792\n",
      "0.7762170507514348\n",
      "0.7957161079646922\n",
      "0.7946529950416195\n",
      "0.78477972889396\n",
      "0.7870044559693572\n",
      "0.0073064362021361936\n",
      "\n",
      " \t ::: 41 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 986, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1, 'n_feat': 15}\n",
      "0.7885941926056539\n",
      "0.7842201773075699\n",
      "0.8003872646563601\n",
      "0.8009096831374215\n",
      "0.7899693622823365\n",
      "0.7928161359978685\n",
      "0.006673034195378121\n",
      "\n",
      " \t ::: 42 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 964, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 10, 'n_feat': 10}\n",
      "0.7834415995232613\n",
      "0.7752369407097202\n",
      "0.7948920863309352\n",
      "0.7913038417239154\n",
      "0.7867586274465779\n",
      "0.7863266191468821\n",
      "0.006776885861540814\n",
      "\n",
      " \t ::: 43 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 295, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'n_feat': 15}\n",
      "0.7862921329970041\n",
      "0.7831012906227806\n",
      "0.8002811367926934\n",
      "0.7993024979782549\n",
      "0.788986546755688\n",
      "0.7915927210292842\n",
      "0.006955889551474184\n",
      "\n",
      " \t ::: 44 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 948, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 10, 'n_feat': 18}\n",
      "0.7869906080865967\n",
      "0.7808334149666528\n",
      "0.7988861676616155\n",
      "0.7986326673147142\n",
      "0.7894422343285318\n",
      "0.7909570184716221\n",
      "0.0069613407086286825\n",
      "\n",
      " \t ::: 45 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 927, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 6, 'n_feat': 24}\n",
      "0.7840722169160563\n",
      "0.7786119682609653\n",
      "0.7959651002602173\n",
      "0.7947091546246905\n",
      "0.7860957627689475\n",
      "0.7878908405661754\n",
      "0.006566349645626814\n",
      "\n",
      " \t ::: 46 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 10, 'n_feat': 15}\n",
      "0.7859023338966034\n",
      "0.7810609678446354\n",
      "0.796589111689372\n",
      "0.7968906991561767\n",
      "0.7893707939475709\n",
      "0.7899627813068717\n",
      "0.006131627274816094\n",
      "\n",
      " \t ::: 47 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 872, 'max_depth': 27, 'min_samples_split': 100, 'min_samples_leaf': 2, 'n_feat': 13}\n",
      "0.7821568951583279\n",
      "0.7769787916636054\n",
      "0.7948349405581917\n",
      "0.7937636314624363\n",
      "0.7831228223441017\n",
      "0.7861714162373327\n",
      "0.006965817058400624\n",
      "\n",
      " \t ::: 48 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 190, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'n_feat': 13}\n",
      "0.7865972375284696\n",
      "0.7803757581694545\n",
      "0.798968824940048\n",
      "0.7958609366193157\n",
      "0.7901091813136458\n",
      "0.7903823877141868\n",
      "0.006607208803281224\n",
      "\n",
      " \t ::: 49 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 815, 'max_depth': 24, 'min_samples_split': 98, 'min_samples_leaf': 1, 'n_feat': 27}\n",
      "0.7792446264867469\n",
      "0.7714547669776897\n",
      "0.7904071636307974\n",
      "0.7897763010643774\n",
      "0.7787899632388211\n",
      "0.7819345642796864\n",
      "0.007214266533638134\n",
      "\n",
      " \t ::: 50 SKOPT CALL ::: \n",
      "\n",
      "{'n_estimators': 725, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'n_feat': 12}\n",
      "0.7908416599319178\n",
      "0.7830211879280646\n",
      "0.8008832083269555\n",
      "0.7997783228093679\n",
      "0.7922238165900894\n",
      "0.793349639117279\n",
      "0.006516394386082404\n"
     ]
    }
   ],
   "source": [
    "search_result_k = optimize('rf', dimensions, init_param, X_train, cv = True, num_calls=50, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qDYdijsY1yb"
   },
   "source": [
    "## Evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost = search_result.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call': 39.0,\n",
       " 'n_estimators': 250.0,\n",
       " 'learning_rate': 0.034591731302067344,\n",
       " 'max_depth': 22.0,\n",
       " 'min_child_weight': 24.0,\n",
       " 'reg_alpha': 1.356787126198538e-06,\n",
       " 'n_feat': 18.0,\n",
       " 'score': -0.7940784631890276}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWHeuKCtY1yv"
   },
   "outputs": [],
   "source": [
    "def evaluate(X_train, X_val, feature_importance, algo, p):\n",
    "    \n",
    "    reduced_feat = feature_importance.iloc[0:int(p['n_feat'])]\n",
    "    reduced_feat = list(reduced_feat['feature'])\n",
    "    y_train = X_train[['label']].values.ravel()\n",
    "    X_train = X_train[reduced_feat].values\n",
    "    y_val = X_val[['label']].values.ravel()\n",
    "    X_val = X_val[reduced_feat].values\n",
    "    \n",
    "    print(len(X_train), len(X_val))\n",
    "    \n",
    "    y_val, y_pred = fit_xgboost(X_train, y_train, X_val, y_val, p)\n",
    "    return roc_auc_score(y_val, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8000579999999999"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_train, X_val, feature_importance, 'xgboost', best_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Higgs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
