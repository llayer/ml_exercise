{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of Higgs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llayer/ml_exercise/blob/master/Higgs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPBJ_Fkqatao",
        "colab_type": "text"
      },
      "source": [
        "# Higgs ML dataset studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYiLaejiY1wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c1bea856-f02e-4368-c4dd-a00e53cfd8a7",
        "id": "7E8GpkJsZeeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/llayer/ml_exercise"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ml_exercise'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 33 (delta 6), reused 21 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMFxP9uzZzAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "1d84a047-8f3d-4bbf-a8ed-5462badf19fe"
      },
      "source": [
        "!pip3 install scikit-optimize"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/87/310b52debfbc0cb79764e5770fa3f5c18f6f0754809ea9e2fc185e1b67d3/scikit_optimize-0.7.4-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.17.5)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/35/1e/eda9fe07f752ced7afcef590e7d74390f0d9c9c0b7ff98317afbaa0697e3/pyaml-19.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-19.12.0 scikit-optimize-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCPA968mZ4t8",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgl4De_IY1wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sig = pd.read_hdf('ml_exercise/higgs_signal.h5')\n",
        "bkg = pd.read_hdf('ml_exercise/higgs_bkg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7TCQ6OY1wp",
        "colab_type": "code",
        "outputId": "260249b5-13e1-4cce-ee56-461697419c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "sig.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lepton_pT</th>\n",
              "      <th>lepton_eta</th>\n",
              "      <th>lepton_phi</th>\n",
              "      <th>missing_energy_magnitude</th>\n",
              "      <th>missing_energy_phi</th>\n",
              "      <th>jet1_pt</th>\n",
              "      <th>jet1_eta</th>\n",
              "      <th>jet1_phi</th>\n",
              "      <th>jet1_btag</th>\n",
              "      <th>jet2_pt</th>\n",
              "      <th>jet2_eta</th>\n",
              "      <th>jet2_phi</th>\n",
              "      <th>jet2_btag</th>\n",
              "      <th>jet3_pt</th>\n",
              "      <th>jet3_eta</th>\n",
              "      <th>jet3_phi</th>\n",
              "      <th>jet3_btag</th>\n",
              "      <th>jet4_pt</th>\n",
              "      <th>jet4_eta</th>\n",
              "      <th>jet4_phi</th>\n",
              "      <th>jet4_btag</th>\n",
              "      <th>m_jj</th>\n",
              "      <th>m_jjj</th>\n",
              "      <th>m_lv</th>\n",
              "      <th>m_jlv</th>\n",
              "      <th>m_bb</th>\n",
              "      <th>m_wbb</th>\n",
              "      <th>m_wwbb</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.723801</td>\n",
              "      <td>-0.914611</td>\n",
              "      <td>0.910944</td>\n",
              "      <td>1.194830</td>\n",
              "      <td>-0.448292</td>\n",
              "      <td>0.839489</td>\n",
              "      <td>-0.871428</td>\n",
              "      <td>0.587799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.654446</td>\n",
              "      <td>1.159881</td>\n",
              "      <td>-0.725923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422018</td>\n",
              "      <td>1.636800</td>\n",
              "      <td>-0.880565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.033994</td>\n",
              "      <td>-0.704196</td>\n",
              "      <td>-0.916982</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>0.867059</td>\n",
              "      <td>1.127180</td>\n",
              "      <td>1.211664</td>\n",
              "      <td>0.695883</td>\n",
              "      <td>0.694068</td>\n",
              "      <td>0.755813</td>\n",
              "      <td>0.761658</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.974119</td>\n",
              "      <td>0.660297</td>\n",
              "      <td>-1.362428</td>\n",
              "      <td>1.234102</td>\n",
              "      <td>1.677716</td>\n",
              "      <td>1.478815</td>\n",
              "      <td>0.408940</td>\n",
              "      <td>-0.105273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.017048</td>\n",
              "      <td>-0.127190</td>\n",
              "      <td>0.363313</td>\n",
              "      <td>2.214872</td>\n",
              "      <td>0.918675</td>\n",
              "      <td>0.072083</td>\n",
              "      <td>1.162631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.961458</td>\n",
              "      <td>0.629154</td>\n",
              "      <td>1.604089</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>1.938668</td>\n",
              "      <td>1.233898</td>\n",
              "      <td>0.990063</td>\n",
              "      <td>0.524871</td>\n",
              "      <td>0.900614</td>\n",
              "      <td>0.917613</td>\n",
              "      <td>1.083369</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.946889</td>\n",
              "      <td>0.169416</td>\n",
              "      <td>1.210014</td>\n",
              "      <td>0.343294</td>\n",
              "      <td>-1.579545</td>\n",
              "      <td>0.999435</td>\n",
              "      <td>1.030804</td>\n",
              "      <td>-0.475041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435374</td>\n",
              "      <td>0.054457</td>\n",
              "      <td>-0.083982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.465033</td>\n",
              "      <td>0.613681</td>\n",
              "      <td>1.492698</td>\n",
              "      <td>2.548224</td>\n",
              "      <td>1.192695</td>\n",
              "      <td>0.190256</td>\n",
              "      <td>0.558635</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>0.881641</td>\n",
              "      <td>0.845381</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.695120</td>\n",
              "      <td>0.787132</td>\n",
              "      <td>0.657668</td>\n",
              "      <td>0.721147</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.298084</td>\n",
              "      <td>-0.897079</td>\n",
              "      <td>1.224441</td>\n",
              "      <td>0.618091</td>\n",
              "      <td>0.856746</td>\n",
              "      <td>0.493122</td>\n",
              "      <td>-0.021810</td>\n",
              "      <td>-1.520042</td>\n",
              "      <td>2.173076</td>\n",
              "      <td>0.973234</td>\n",
              "      <td>0.325470</td>\n",
              "      <td>-0.250431</td>\n",
              "      <td>2.214872</td>\n",
              "      <td>0.782569</td>\n",
              "      <td>-0.841807</td>\n",
              "      <td>-0.817325</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.810789</td>\n",
              "      <td>-1.033162</td>\n",
              "      <td>0.581386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.848238</td>\n",
              "      <td>0.925814</td>\n",
              "      <td>0.973957</td>\n",
              "      <td>0.961469</td>\n",
              "      <td>0.946147</td>\n",
              "      <td>1.028120</td>\n",
              "      <td>0.848133</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.022289</td>\n",
              "      <td>-0.481195</td>\n",
              "      <td>0.169649</td>\n",
              "      <td>1.103255</td>\n",
              "      <td>0.744424</td>\n",
              "      <td>1.648197</td>\n",
              "      <td>-0.780327</td>\n",
              "      <td>-1.484007</td>\n",
              "      <td>2.173076</td>\n",
              "      <td>0.675472</td>\n",
              "      <td>0.507117</td>\n",
              "      <td>0.395493</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.540036</td>\n",
              "      <td>0.139441</td>\n",
              "      <td>-0.549385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.802513</td>\n",
              "      <td>-1.164748</td>\n",
              "      <td>-0.284934</td>\n",
              "      <td>1.550981</td>\n",
              "      <td>0.717778</td>\n",
              "      <td>0.752909</td>\n",
              "      <td>0.996800</td>\n",
              "      <td>1.648921</td>\n",
              "      <td>1.138676</td>\n",
              "      <td>1.118826</td>\n",
              "      <td>0.977200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lepton_pT  lepton_eta  lepton_phi  ...     m_wbb    m_wwbb  label\n",
              "0   0.723801   -0.914611    0.910944  ...  0.755813  0.761658      0\n",
              "1   1.974119    0.660297   -1.362428  ...  0.917613  1.083369      0\n",
              "2   0.946889    0.169416    1.210014  ...  0.657668  0.721147      0\n",
              "3   1.298084   -0.897079    1.224441  ...  1.028120  0.848133      0\n",
              "4   1.022289   -0.481195    0.169649  ...  1.118826  0.977200      0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4WBvBRsY1wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([sig, bkg])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz6Kr_wHbLCn",
        "colab_type": "text"
      },
      "source": [
        "## 2. Feature importance with XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ln3DtclY1w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = data.drop(['label'], axis=1).values\n",
        "labels = data[['label']].values.ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1xi50WHcVgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1szgLItqcDqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "95445b56-bd11-4544-8b3a-cfa719742cb0"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Early stopping\n",
        "early_stopping_rounds = 5\n",
        "\n",
        "# Define model\n",
        "model_bdt = xgb.XGBClassifier(n_jobs = 4)\n",
        "\n",
        "# Last in list is used for early stopping\n",
        "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "\n",
        "# Fit with early stopping\n",
        "model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
        "              early_stopping_rounds=early_stopping_rounds, verbose=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=4,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCyOAN21cgh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "95dd3154-6b0d-4cb2-bea5-64cac980a857"
      },
      "source": [
        "from xgboost import plot_importance\n",
        "plot_importance(model_bdt)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7eff3ba30b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtRPZjKHchG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fscore = list(model_bdt.feature_importances_)\n",
        "feature_importance = pd.DataFrame(list(data.drop(['label'], axis=1)))\n",
        "feature_importance['f-score'] = fscore\n",
        "feature_importance.columns = ['feature', 'fscore']\n",
        "feature_importance = feature_importance.sort_values(by=['fscore'], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_REzjOrwdDFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3ed1b969-7b6e-4027-fbcd-f04b84b04d10"
      },
      "source": [
        "feature_importance.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>fscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>m_bb</td>\n",
              "      <td>0.147746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>m_wbb</td>\n",
              "      <td>0.101843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>m_wwbb</td>\n",
              "      <td>0.073595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>jet1_pt</td>\n",
              "      <td>0.069575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>m_jjj</td>\n",
              "      <td>0.068811</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    feature    fscore\n",
              "25     m_bb  0.147746\n",
              "26    m_wbb  0.101843\n",
              "27   m_wwbb  0.073595\n",
              "5   jet1_pt  0.069575\n",
              "22    m_jjj  0.068811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWiqfCYZdxai",
        "colab_type": "text"
      },
      "source": [
        "## Test algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTY8ZTRaeIbK",
        "colab_type": "text"
      },
      "source": [
        "### Set up Bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JadlZZmLd7O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "import skopt\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import gp_minimize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def fit_lreg(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "    predictions = model_bdt.clf(X_test)[:,1]\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "\n",
        "def fit_xgboost(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping_rounds = 10\n",
        "    # Define model\n",
        "    model_bdt = xgb.XGBClassifier(n_jobs = 4, n_estimators = 1000, learning_rate = p['learning_rate'],\n",
        "                            max_depth = p['max_depth'], min_child_weight = p['min_child_weight'])\n",
        "    # Last in list is used for early stopping\n",
        "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "    # Fit with early stopping\n",
        "    model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
        "                    early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
        "    predictions = model_bdt.predict_proba(X_test)[:,1]\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "def fit_keras(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    # Early stopping\n",
        "    patience = 5\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=patience)\n",
        "    \n",
        "    # Define model\n",
        "    model = create_model(features.shape[1], p['dense_layers'], p['dense_units'], 0., \n",
        "                            #p['regulizer_value'], \n",
        "                            p['dropout_value'], \n",
        "                            p['learning_rate'])\n",
        "    \n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100,# p['batch_size'], \n",
        "                        epochs=1000, verbose=0, callbacks=[es])\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "\n",
        "def optimize( algo, dimensions, initial_param, data, cv = False, kfold_splits = 5, num_calls=12, random_state = 42): \n",
        "\n",
        "    prior_values = []\n",
        "    prior_names = []\n",
        "    for var in dimensions:\n",
        "        name = var.name\n",
        "        print( name )\n",
        "        prior_names.append(name)\n",
        "        prior_values.append(initial_param[name])\n",
        "\n",
        "    global num_skopt_call\n",
        "    num_skopt_call = 0\n",
        "    #errors = []\n",
        "\n",
        "    @use_named_args(dimensions)\n",
        "    def fitness(**p): \n",
        "\n",
        "        global num_skopt_call\n",
        "\n",
        "        print('\\n \\t ::: {} SKOPT CALL ::: \\n'.format(num_skopt_call+1))\n",
        "        print(p)\n",
        "\n",
        "        reduced_feat = feature_importance.iloc[0:p['n_feat']]\n",
        "        reduced_feat = list(reduced_feat['feature'])\n",
        "        data_red = data[reduced_feat]\n",
        "        features = data_red.values\n",
        "        labels = data[['label']].values.ravel()\n",
        "\n",
        "        if cv == False:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=random_state)\n",
        "            if algo == 'xgboost':\n",
        "                score = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
        "            if algo == 'keras':\n",
        "                score = fit_keras(X_train, y_train, X_test, y_test, p)\n",
        "            print(score)\n",
        "\n",
        "        else:\n",
        "            cv_scores = []    \n",
        "            enum = enumerate(KFold(n_splits=kfold_splits, shuffle=True, random_state=random_state).split(features,labels))\n",
        "            for i,(index_train, index_valid) in enum:\n",
        "                X_train, X_test = features[ index_train ], features[ index_valid ]\n",
        "                y_train, y_test = labels[ index_train ], labels[ index_valid ]   \n",
        "                if algo == 'xgboost':\n",
        "                    score = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
        "                if algo == 'keras':\n",
        "                    score = fit_keras(X_train, y_train, X_test, y_test, p)\n",
        "                cv_scores.append(score)\n",
        "                print( cv_scores )\n",
        "            score = np.mean(cv_scores)\n",
        "            print(score)\n",
        "            print(np.std(cv_scores))\n",
        "\n",
        "        num_skopt_call += 1\n",
        "\n",
        "        return -1*score\n",
        "\n",
        "    search_result = gp_minimize( func = fitness, dimensions = dimensions,\n",
        "                                 acq_func = 'EI', # Expected Improvement\n",
        "                                 n_calls = num_calls, x0 = prior_values )\n",
        "\n",
        "    params = pd.DataFrame(search_result['x_iters'])\n",
        "    params.columns = [*prior_names]\n",
        "    params = params.rename_axis('call').reset_index()\n",
        "    scores = pd.DataFrame(search_result['func_vals'])\n",
        "    scores.columns = ['score']\n",
        "    result = pd.concat([params, scores], axis=1)\n",
        "    result = result.sort_values(by=['score'])\n",
        "    #errors_frame = pd.DataFrame(errors, columns = ['call', 'q_error', 't_error'])\n",
        "    #result = pd.merge(result, errors_frame, on=['call'])   \n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r236T_l7d2AK",
        "colab_type": "text"
      },
      "source": [
        "### 1. XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Oz0bOrMdCs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "# Skopt dimensions\n",
        "skopt_dims = [       \n",
        "    Real(        low=1e-2, high=1,     prior='log-uniform', name='learning_rate'     ),\n",
        "    Integer(        low=2,    high=20,                         name='max_depth'     ),\n",
        "    Integer(        low=1,    high=20,                         name='min_child_weight'     ),\n",
        "    Real(        low=1e-6, high=1e-2,     prior='log-uniform', name='reg_alpha'     ),\n",
        "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
        "\n",
        "]\n",
        "\n",
        "# Initial parameters\n",
        "init_param = {'learning_rate' : 0.3, 'reg_alpha' : 1e-5, 'max_depth' : 6, 'min_child_weight' : 1, 'n_feat':12 }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUaHPgdeevWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "0c8d5b9a-4517-4461-dc68-0cbf1f7c94a9"
      },
      "source": [
        "search_result = optimize('xgboost', skopt_dims, init_param, data, cv = True, num_calls=20, random_state = 42)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning_rate\n",
            "max_depth\n",
            "min_child_weight\n",
            "reg_alpha\n",
            "n_feat\n",
            "\n",
            " \t ::: 1 SKOPT CALL ::: \n",
            "\n",
            "{'learning_rate': 0.3, 'max_depth': 6, 'min_child_weight': 1, 'reg_alpha': 1e-05, 'n_feat': 12}\n",
            "[0.7754328578154179]\n",
            "[0.7754328578154179, 0.7919428262996222]\n",
            "[0.7754328578154179, 0.7919428262996222, 0.779414937729251]\n",
            "[0.7754328578154179, 0.7919428262996222, 0.779414937729251, 0.7957423210858326]\n",
            "[0.7754328578154179, 0.7919428262996222, 0.779414937729251, 0.7957423210858326, 0.7997038066424149]\n",
            "0.7884473499145077\n",
            "0.00941386479718343\n",
            "\n",
            " \t ::: 2 SKOPT CALL ::: \n",
            "\n",
            "{'learning_rate': 0.018860930104911692, 'max_depth': 3, 'min_child_weight': 9, 'reg_alpha': 1.68374180887052e-05, 'n_feat': 15}\n",
            "[0.7830459198942705]\n",
            "[0.7830459198942705, 0.7926927104857034]\n",
            "[0.7830459198942705, 0.7926927104857034, 0.7865555786405567]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-843146852495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgboost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskopt_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-e25da49e73cf>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(algo, dimensions, initial_param, data, cv, kfold_splits, num_calls, random_state)\u001b[0m\n\u001b[1;32m    101\u001b[0m     search_result = gp_minimize( func = fitness, dimensions = dimensions,\n\u001b[1;32m    102\u001b[0m                                  \u001b[0macq_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                  n_calls = num_calls, x0 = prior_values )\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-e25da49e73cf>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(**p)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mindex_train\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mindex_valid\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'xgboost'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'keras'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-e25da49e73cf>\u001b[0m in \u001b[0;36mfit_xgboost\u001b[0;34m(X_train, y_train, X_test, y_test, p)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Fit with early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n\u001b[0;32m---> 22\u001b[0;31m                     early_stopping_rounds=early_stopping_rounds, verbose=False)\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaC2QkDngdWI",
        "colab_type": "text"
      },
      "source": [
        "### 2. Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMJ02LakiRc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Reshape\n",
        "\n",
        "def create_model( n_features, dense_layers, dense_units, regulizer_value, dropout_value, learning_rate ):\n",
        "\n",
        "    m_input = Input(shape = (n_features, ))\n",
        "    m = m_input\n",
        "    \n",
        "    for _ in range(dense_layers):\n",
        "        m = Dense( units=dense_units, activation='relu', \n",
        "                   kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
        "        m = Dropout(dropout_value)(m)\n",
        "\n",
        "    m_output = Dense( units=1, activation='sigmoid', \n",
        "                      kernel_initializer='lecun_normal',\n",
        "                      kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
        "\n",
        "    model = keras.models.Model(inputs=m_input, outputs=m_output)\n",
        "    model.compile( loss = 'binary_crossentropy',\n",
        "                        optimizer = keras.optimizers.Adam(lr=learning_rate) )\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqB7c3v4ipkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimensions = [\n",
        "    Integer(     low=1,    high=5,                        name='dense_layers'      ),\n",
        "    #Integer(     low=100,    high=1000,                    name='batch_size'      ),\n",
        "    Integer(     low=5,    high=200,                        name='dense_units'       ),\n",
        "    #Real(        low=1e-3, high=0.9,  prior=\"log-uniform\", name='regulizer_value'   ),\n",
        "    Real(        low=1e-3, high=0.5,   prior=\"log-uniform\",                    name='dropout_value'     ),\n",
        "    Real(        low=1e-4, high=1e-1, prior='log-uniform', name='learning_rate'     ),\n",
        "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Initial parameters\n",
        "init_param = {'learning_rate' : 1e-2, 'dense_layers' : 3, 'regulizer_value' : 1e-2, 'dropout_value': 0.02, \n",
        "             'dense_units' : 20, 'batch_size' : 100, 'n_feat': 20}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7oIVki7gT9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f01aaba-290b-4c5d-a476-b1678c0353b4"
      },
      "source": [
        "search_result = optimize('keras', dimensions, init_param, data, \n",
        "                             num_calls=100, random_seed = 1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_layers\n",
            "dense_units\n",
            "dropout_value\n",
            "learning_rate\n",
            "n_feat\n",
            "\n",
            " \t ::: 1 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 3, 'dense_units': 20, 'dropout_value': 0.02, 'learning_rate': 0.01, 'n_feat': 20}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "0.7508112593510607\n",
            "0.732589679331526\n",
            "\n",
            " \t ::: 2 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 3, 'dense_units': 118, 'dropout_value': 0.17048057837730596, 'learning_rate': 0.015821751648560967, 'n_feat': 25}\n",
            "0.7351910179471172\n",
            "0.7067717534476262\n",
            "\n",
            " \t ::: 3 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 2, 'dense_units': 28, 'dropout_value': 0.002301067637042528, 'learning_rate': 0.01276450744457826, 'n_feat': 18}\n",
            "0.7654692973864804\n",
            "0.7398850085667772\n",
            "\n",
            " \t ::: 4 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 4, 'dense_units': 23, 'dropout_value': 0.010938015249127688, 'learning_rate': 0.00010303403289138984, 'n_feat': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cb6409180785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m search_result = optimize('keras', dimensions, init_param, data, \n\u001b[0;32m----> 2\u001b[0;31m                              num_calls=100, random_seed = 1)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-ee468d61ffcf>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(algo, dimensions, initial_param, data, num_calls, random_seed)\u001b[0m\n\u001b[1;32m     84\u001b[0m     search_result = gp_minimize( func = fitness, dimensions = dimensions,\n\u001b[1;32m     85\u001b[0m                                  \u001b[0macq_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                  n_calls = num_calls, x0 = prior_values )\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ee468d61ffcf>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(**p)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100,# p['batch_size'], \n\u001b[0;32m---> 71\u001b[0;31m                                 epochs=1000, verbose=0, callbacks=[es])\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cduM1_sxcsQP",
        "colab_type": "text"
      },
      "source": [
        "## Genetic Algorithm for feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ycfTELvY1w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples = features.shape[0]\n",
        "num_feature_elements = features.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXpnXamrY1xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sol_per_pop = 12 # Population size.\n",
        "num_parents_mating = 6 # Number of parents inside the mating pool.\n",
        "num_mutations = 3 # Number of elements to mutate.\n",
        "\n",
        "# Defining the population shape.\n",
        "pop_shape = (sol_per_pop, num_feature_elements)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd5XxoAiY1xF",
        "colab_type": "code",
        "outputId": "17b2d372-e843-40b0-ca13-42d9db3ce4d4",
        "colab": {}
      },
      "source": [
        "# Creating the initial population.\n",
        "new_population = np.random.randint(low=0, high=2, size=pop_shape)\n",
        "print(new_population.shape)\n",
        "\n",
        "best_outputs = []\n",
        "num_generations = 100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Out3kF2Y1xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ga"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOj8smL2Y1xP",
        "colab_type": "code",
        "outputId": "8d7c37b8-cd67-4ebb-f24a-a08c8e0ec9ea",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "importlib.reload(ga)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'ga' from '/eos/home-l/llayer/Higgs/ga.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eUeEDUgRY1xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for generation in range(num_generations):\n",
        "    print(\"Generation : \", generation)\n",
        "    \n",
        "    # Measuring the fitness of each chromosome in the population.\n",
        "    fitness = ga.cal_pop_fitness(new_population, features, labels)\n",
        "\n",
        "    print( fitness )\n",
        "    \n",
        "    best_outputs.append(np.max(fitness))\n",
        "    # The best result in the current iteration.\n",
        "    print(\"Best result : \", best_outputs[-1])\n",
        "\n",
        "    # Selecting the best parents in the population for mating.\n",
        "    parents = ga.select_mating_pool(new_population, fitness, num_parents_mating)\n",
        "\n",
        "    # Generating next generation using crossover.\n",
        "    offspring_crossover = ga.crossover(parents, offspring_size=(pop_shape[0]-parents.shape[0], num_feature_elements))\n",
        "\n",
        "    # Adding some variations to the offspring using mutation.\n",
        "    offspring_mutation = ga.mutation(offspring_crossover, num_mutations=num_mutations)\n",
        "\n",
        "    # Creating the new population based on the parents and offspring.\n",
        "    new_population[0:parents.shape[0], :] = parents\n",
        "    new_population[parents.shape[0]:, :] = offspring_mutation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFyEdZJAY1xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1lCk6djY1xY",
        "colab_type": "code",
        "outputId": "06179466-334e-46a6-d821-b80af41eb9fa",
        "colab": {}
      },
      "source": [
        "\n",
        "# Getting the best solution after iterating finishing all generations.\n",
        "# At first, the fitness is calculated for each solution in the final generation.\n",
        "fitness = ga.cal_pop_fitness(new_population, features, labels)\n",
        "# Then return the index of that solution corresponding to the best fitness.\n",
        "best_match_idx = np.where(fitness == np.max(fitness))[0]\n",
        "best_match_idx = best_match_idx[0]\n",
        "\n",
        "best_solution = new_population[best_match_idx, :]\n",
        "best_solution_indices = np.where(best_solution == 1)[0]\n",
        "best_solution_num_elements = best_solution_indices.shape[0]\n",
        "best_solution_fitness = fitness[best_match_idx]\n",
        "\n",
        "print(\"best_match_idx : \", best_match_idx)\n",
        "print(\"best_solution : \", best_solution)\n",
        "print(\"Selected indices : \", best_solution_indices)\n",
        "print(\"Number of selected elements : \", best_solution_num_elements)\n",
        "print(\"Best solution fitness : \", best_solution_fitness)\n",
        "\n",
        "plt.plot(best_outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7822324019697021\n",
            "0.7819253075467076\n",
            "0.7818933032385696\n",
            "0.7818724568169131\n",
            "0.7818649263914688\n",
            "0.7818597836618972\n",
            "0.7717151526577948\n",
            "0.7714571437518729\n",
            "0.7712103386496606\n",
            "0.7722144565985307\n",
            "0.7714556284833383\n",
            "0.7720901127442441\n",
            "best_match_idx :  0\n",
            "best_solution :  [1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "Selected indices :  [ 0  2  3  4  5  8  9 12 13 14 15 16 18 19 20 21 22 23 24 25 26 27]\n",
            "Number of selected elements :  22\n",
            "Best solution fitness :  0.7822324019697021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f74e890a518>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tphFZpHeY1xb",
        "colab_type": "code",
        "outputId": "b2451c9e-42e9-43f5-8282-1918722a9853",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import sklearn.svm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "SV_classifier = sklearn.svm.SVC(gamma='scale')\n",
        "SV_classifier.fit(X=X_train, y=y_train)\n",
        "\n",
        "predictions = SV_classifier.decision_function(X_test)#.predict(X_test)\n",
        "score = roc_auc_score(y_test, predictions) # classification_accuracy(y_test, predictions)\n",
        "print(score)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nSV_classifier = sklearn.svm.SVC(gamma='scale')\\nSV_classifier.fit(X=X_train, y=y_train)\\n\\npredictions = SV_classifier.decision_function(X_test)#.predict(X_test)\\nscore = roc_auc_score(y_test, predictions) # classification_accuracy(y_test, predictions)\\nprint(score)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOdN441PY1xr",
        "colab_type": "code",
        "outputId": "6e5fd833-728c-4a73-dfff-49aae07f618a",
        "colab": {}
      },
      "source": [
        "predictions = model_bdt.predict_proba(X_test)[:,1]\n",
        "score = roc_auc_score(y_test, predictions)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7805039397441069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtaCUF7uY1yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fitness = pd.DataFrame(best_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwycEN_sY1yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fitness.to_hdf('xgb_sol_12_parents_6_mutations_3.h5', 'frame')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsIUPtMRY1yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSW4s8suY1yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qDYdijsY1yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHeuKCtY1yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}