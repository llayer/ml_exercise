{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of Higgs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llayer/ml_exercise/blob/master/Higgs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPBJ_Fkqatao",
        "colab_type": "text"
      },
      "source": [
        "# Higgs ML dataset studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYiLaejiY1wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9e13fca5-b374-4e28-8b83-40f5a83eda7d",
        "id": "7E8GpkJsZeeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/llayer/ml_exercise"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ml_exercise' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMFxP9uzZzAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b519ef4c-bd8b-4d5a-dfa0-7c5c7bf1a72a"
      },
      "source": [
        "!pip3 install scikit-optimize"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (19.12.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.14.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx6G1hOJJ5EU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49f0970e-ec43-44c4-b184-d68098343a08"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ml_exercise  sample_data  xgboost.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCPA968mZ4t8",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgl4De_IY1wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sig = pd.read_hdf('ml_exercise/higgs_signal.h5')\n",
        "bkg = pd.read_hdf('ml_exercise/higgs_bkg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7TCQ6OY1wp",
        "colab_type": "code",
        "outputId": "5cbd3b57-8425-4154-811f-a68a1eb36f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "sig.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lepton_pT</th>\n",
              "      <th>lepton_eta</th>\n",
              "      <th>lepton_phi</th>\n",
              "      <th>missing_energy_magnitude</th>\n",
              "      <th>missing_energy_phi</th>\n",
              "      <th>jet1_pt</th>\n",
              "      <th>jet1_eta</th>\n",
              "      <th>jet1_phi</th>\n",
              "      <th>jet1_btag</th>\n",
              "      <th>jet2_pt</th>\n",
              "      <th>jet2_eta</th>\n",
              "      <th>jet2_phi</th>\n",
              "      <th>jet2_btag</th>\n",
              "      <th>jet3_pt</th>\n",
              "      <th>jet3_eta</th>\n",
              "      <th>jet3_phi</th>\n",
              "      <th>jet3_btag</th>\n",
              "      <th>jet4_pt</th>\n",
              "      <th>jet4_eta</th>\n",
              "      <th>jet4_phi</th>\n",
              "      <th>jet4_btag</th>\n",
              "      <th>m_jj</th>\n",
              "      <th>m_jjj</th>\n",
              "      <th>m_lv</th>\n",
              "      <th>m_jlv</th>\n",
              "      <th>m_bb</th>\n",
              "      <th>m_wbb</th>\n",
              "      <th>m_wwbb</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.723801</td>\n",
              "      <td>-0.914611</td>\n",
              "      <td>0.910944</td>\n",
              "      <td>1.194830</td>\n",
              "      <td>-0.448292</td>\n",
              "      <td>0.839489</td>\n",
              "      <td>-0.871428</td>\n",
              "      <td>0.587799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.654446</td>\n",
              "      <td>1.159881</td>\n",
              "      <td>-0.725923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422018</td>\n",
              "      <td>1.636800</td>\n",
              "      <td>-0.880565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.033994</td>\n",
              "      <td>-0.704196</td>\n",
              "      <td>-0.916982</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>0.867059</td>\n",
              "      <td>1.127180</td>\n",
              "      <td>1.211664</td>\n",
              "      <td>0.695883</td>\n",
              "      <td>0.694068</td>\n",
              "      <td>0.755813</td>\n",
              "      <td>0.761658</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.974119</td>\n",
              "      <td>0.660297</td>\n",
              "      <td>-1.362428</td>\n",
              "      <td>1.234102</td>\n",
              "      <td>1.677716</td>\n",
              "      <td>1.478815</td>\n",
              "      <td>0.408940</td>\n",
              "      <td>-0.105273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.017048</td>\n",
              "      <td>-0.127190</td>\n",
              "      <td>0.363313</td>\n",
              "      <td>2.214872</td>\n",
              "      <td>0.918675</td>\n",
              "      <td>0.072083</td>\n",
              "      <td>1.162631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.961458</td>\n",
              "      <td>0.629154</td>\n",
              "      <td>1.604089</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>1.938668</td>\n",
              "      <td>1.233898</td>\n",
              "      <td>0.990063</td>\n",
              "      <td>0.524871</td>\n",
              "      <td>0.900614</td>\n",
              "      <td>0.917613</td>\n",
              "      <td>1.083369</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.946889</td>\n",
              "      <td>0.169416</td>\n",
              "      <td>1.210014</td>\n",
              "      <td>0.343294</td>\n",
              "      <td>-1.579545</td>\n",
              "      <td>0.999435</td>\n",
              "      <td>1.030804</td>\n",
              "      <td>-0.475041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435374</td>\n",
              "      <td>0.054457</td>\n",
              "      <td>-0.083982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.465033</td>\n",
              "      <td>0.613681</td>\n",
              "      <td>1.492698</td>\n",
              "      <td>2.548224</td>\n",
              "      <td>1.192695</td>\n",
              "      <td>0.190256</td>\n",
              "      <td>0.558635</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>0.881641</td>\n",
              "      <td>0.845381</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.695120</td>\n",
              "      <td>0.787132</td>\n",
              "      <td>0.657668</td>\n",
              "      <td>0.721147</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.298084</td>\n",
              "      <td>-0.897079</td>\n",
              "      <td>1.224441</td>\n",
              "      <td>0.618091</td>\n",
              "      <td>0.856746</td>\n",
              "      <td>0.493122</td>\n",
              "      <td>-0.021810</td>\n",
              "      <td>-1.520042</td>\n",
              "      <td>2.173076</td>\n",
              "      <td>0.973234</td>\n",
              "      <td>0.325470</td>\n",
              "      <td>-0.250431</td>\n",
              "      <td>2.214872</td>\n",
              "      <td>0.782569</td>\n",
              "      <td>-0.841807</td>\n",
              "      <td>-0.817325</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.810789</td>\n",
              "      <td>-1.033162</td>\n",
              "      <td>0.581386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.848238</td>\n",
              "      <td>0.925814</td>\n",
              "      <td>0.973957</td>\n",
              "      <td>0.961469</td>\n",
              "      <td>0.946147</td>\n",
              "      <td>1.028120</td>\n",
              "      <td>0.848133</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.022289</td>\n",
              "      <td>-0.481195</td>\n",
              "      <td>0.169649</td>\n",
              "      <td>1.103255</td>\n",
              "      <td>0.744424</td>\n",
              "      <td>1.648197</td>\n",
              "      <td>-0.780327</td>\n",
              "      <td>-1.484007</td>\n",
              "      <td>2.173076</td>\n",
              "      <td>0.675472</td>\n",
              "      <td>0.507117</td>\n",
              "      <td>0.395493</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.540036</td>\n",
              "      <td>0.139441</td>\n",
              "      <td>-0.549385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.802513</td>\n",
              "      <td>-1.164748</td>\n",
              "      <td>-0.284934</td>\n",
              "      <td>1.550981</td>\n",
              "      <td>0.717778</td>\n",
              "      <td>0.752909</td>\n",
              "      <td>0.996800</td>\n",
              "      <td>1.648921</td>\n",
              "      <td>1.138676</td>\n",
              "      <td>1.118826</td>\n",
              "      <td>0.977200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lepton_pT  lepton_eta  lepton_phi  ...     m_wbb    m_wwbb  label\n",
              "0   0.723801   -0.914611    0.910944  ...  0.755813  0.761658      0\n",
              "1   1.974119    0.660297   -1.362428  ...  0.917613  1.083369      0\n",
              "2   0.946889    0.169416    1.210014  ...  0.657668  0.721147      0\n",
              "3   1.298084   -0.897079    1.224441  ...  1.028120  0.848133      0\n",
              "4   1.022289   -0.481195    0.169649  ...  1.118826  0.977200      0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4WBvBRsY1wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([sig, bkg])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnoSsoG8df2h",
        "colab_type": "text"
      },
      "source": [
        "### Split data in train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y4nYcXHde4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prep_data(data, val_size = 0.2):\n",
        "\n",
        "    features = data.drop(['label'], axis=1)\n",
        "    labels = data[['label']].values.ravel()\n",
        "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=val_size, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "X_train, X_val, y_train, y_val = prep_data(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz6Kr_wHbLCn",
        "colab_type": "text"
      },
      "source": [
        "## 2. Feature importance with XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1szgLItqcDqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "\n",
        "def get_feature_importance(X, y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.33, random_state=42)\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping_rounds = 5\n",
        "\n",
        "    # Define model\n",
        "    model_bdt = xgb.XGBClassifier(n_jobs = 4)\n",
        "\n",
        "    # Last in list is used for early stopping\n",
        "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "\n",
        "    # Fit with early stopping\n",
        "    model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
        "                early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
        "    \n",
        "    plot_importance(model_bdt)\n",
        "    fscore = list(model_bdt.feature_importances_)\n",
        "    feature_importance = pd.DataFrame(list(data.drop(['label'], axis=1)))\n",
        "    feature_importance['f-score'] = fscore\n",
        "    feature_importance.columns = ['feature', 'fscore']\n",
        "    feature_importance = feature_importance.sort_values(by=['fscore'], ascending=False)\n",
        "\n",
        "    return feature_importance\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCyOAN21cgh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ede8c6b9-1398-45cd-ea63-584f9c65b0e4"
      },
      "source": [
        "feature_importance = get_feature_importance(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU5fX48c9BiCCrC2uARFTWoEGo\n4Fe/EEQQ0Irbry6odaEutIJVRK2tUtuqVVARqSIIClqoIohFvi5lESqiggZBIUqFSgDZBGRTSHJ+\nfzw3cQgzyQBz5yZzz/v1mlcyd+7cex5G58l97nnOI6qKMcaY8KoSdADGGGOCZR2BMcaEnHUExhgT\nctYRGGNMyFlHYIwxIWcdgTHGhJx1BMbESUSeFZE/BB2HMYkmNo/A+E1E1gANgcKIzS1Vdf0RHDMH\neElVmx5ZdJWTiLwA5Kvq74OOxVR+dkVgkuXnqlor4nHYnUAiiEjVIM9/JETkqKBjMKnFOgITKBHp\nIiILRWS7iCz1/tIvfu16EVkhIjtF5GsRudnbXhP4P6CJiOzyHk1E5AUR+XPE+3NEJD/i+RoRuVtE\nPgN2i0hV732vichmEVktIoPKiLXk+MXHFpGhIrJJRDaIyEUi0ldEvhSR70TkdxHvHSYiU0XkH157\nPhGR0yJebyMi87x/h89F5MJS531GRGaJyG7gRqA/MNRr+z+9/e4Rkf94x/9CRC6OOMZ1IvJvERku\nItu8tvaJeP04EZkgIuu911+PeO0CEcn1YlsoIqfG/QGbSsE6AhMYEUkH3gT+DBwHDAFeE5H63i6b\ngAuAOsD1wBMicrqq7gb6AOsP4wrjSuB8oB5QBPwTWAqkAz2A20XkvDiP1Qio7r33fmAscDXQEfhf\n4A8icmLE/v2AV722/h14XUSqiUg1L453gAbAbcDLItIq4r1XAX8BagMTgZeBR722/9zb5z/eeesC\nfwReEpHGEcfoDOQBJwCPAs+LiHivTQKOAdp5MTwBICIdgPHAzcDxwBjgDRE5Os5/I1MJWEdgkuV1\n7y/K7RF/bV4NzFLVWapapKrvAouBvgCq+qaq/ked93BflP97hHE8paprVXUv8DOgvqo+qKr7VPVr\n3Jf5FXEeaz/wF1XdD0zBfcGOVNWdqvo58AVwWsT+S1R1qrf/47hOpIv3qAU84sUxB5iJ67SKzVDV\n971/px+iBaOqr6rqem+ffwBfAWdE7PJfVR2rqoXAi0BjoKHXWfQBblHVbaq63/v3BrgJGKOqH6pq\noaq+CPzoxWxSRKUdJzWVzkWq+q9S2zKA/yciP4/YVg2YC+ANXTwAtMT90XIMsOwI41hb6vxNRGR7\nxLajgAVxHmur96UKsNf7uTHi9b24L/iDzq2qRd6wVZPi11S1KGLf/+KuNKLFHZWIXAvcAWR6m2rh\nOqdi30acf493MVALd4Xynapui3LYDOCXInJbxLa0iLhNCrCOwARpLTBJVX9V+gVv6OE14FrcX8P7\nvSuJ4qGMaOluu3GdRbFGUfaJfN9aYLWqnnI4wR+GZsW/iEgVoClQPKTVTESqRHQGzYEvI95bur0H\nPBeRDNzVTA/gA1UtFJFcfvr3Ksta4DgRqaeq26O89hdV/UscxzGVlA0NmSC9BPxcRM4TkaNEpLp3\nE7Yp7q/Oo4HNQIF3ddAr4r0bgeNFpG7Etlygr3fjsxFweznn/wjY6d1AruHFkCUiP0tYCw/UUUQu\n8TKWbscNsSwCPgT24G7+VvNumP8cN9wUy0agRcTzmrjOYTO4G+1AVjxBqeoG3M33v4nIsV4MXb2X\nxwK3iEhncWqKyPkiUjvONptKwDoCExhVXYu7gfo73BfYWuAuoIqq7gQGAa8A23A3S9+IeO9KYDLw\ntXffoQnuhudSYA3ufsI/yjl/Ie5mdDawGtgCjMPdbPXDDOByXHuuAS7xxuP34b74+3gx/A241mtj\nLM8DbYvvuajqF8AI4ANcJ9EeeP8QYrsGd89jJe4m/e0AqroY+BXwtBf3KuC6QziuqQRsQpkxSSAi\nw4CTVfXqoGMxpjS7IjDGmJCzjsAYY0LOhoaMMSbk7IrAGGNCrlLOI6hXr56efPLJQYeRdLt376Zm\nzZpBh5F01u5wsXb7Y8mSJVtUtX601yplR9CwYUMWL14cdBhJN2/ePHJycoIOI+ms3eFi7faHiPw3\n1ms2NGSMMSFnHYExxoScdQTGGBOwkSNHcv3119OuXTuefPJJAHJzc+nSpQvZ2dl06tSJjz76yLfz\n+9YRiMggcYuKqIh8JiLLvEUtIhfjWONtzxWR8A36G2NCb/ny5YwdO5ZnnnmGpUuXMnPmTFatWsXQ\noUN54IEHyM3N5cEHH2To0KG+xeDnzeKBwLm4KoorVHWbVzjsOdwCGcW6q+oWH+MwxpgKa8WKFXTu\n3Jnq1atTtWpVunXrxrRp0xARvv/+ewB27NhBkyb+Vf72ZUKZiDwL3IBbDWm8qhavdnQssFxV073n\na4BOh9oRNG9xslb5xcjEBl0J3Nm+gBHLKmWi1xGxdodLqrd7zSPnH/B8xYoV9OvXj8cee4yePXvS\no0cPOnXqxMCBAznvvPNQVYqKili4cCEZGRmHfV4RWaKqnaK+5tfM4mhf8iIyBGitqgO856txFQ0V\ntwrSc2Uc7ybcakmccEL9jvc/OdaXuCuyhjVg497y90s11u5wSfV2t08/uLjtm2++yfTp06lZsyaZ\nmZlUq1aNoqIiTjvtNLp168bcuXOZOXMmI0aMOOzzdu/ePWZHgKr68sCVAj4h4nl3YAVwfMS2dO9n\nA1z54K7xHLtly5YaRnPnzg06hEBYu8Ml7O2+9957dfTo0VqnTh0tKipSVdWioiKtXbv2ER0fWKwx\nvlOTkjUkIqfi6rz3U9WtEZ3QOu/nJmA6B66vaowxobBp0yYAvvnmG6ZNm8ZVV11FkyZNeO89t3T0\nnDlzOOUU/xbS830gTkSaA9OAa1T1y4jtNfEWIPF+7wU86Hc8xpiKIy8vj8svv7zk+ddff821117L\nM888Q15eHgDbt2+nXr165ObmBhWm7y699FLWrl1L3bp1GT16NPXq1WPs2LEMHjyYgoICqlevznPP\nxRw5P2J+dgS1gYXAKUAhMFtEioA1qtoO6ALM9BbQBre2amvgLR9jMsZUIK1atSr5gi8sLCQ9PZ2z\nzz6bK664omSfO++8k7p1/Vo0rmJYsGDBQSUmzj77bJYsWZKU8/s5NLQZOAc4C6ivqjWAy4BdAKo6\nW1VreNtrAdtxw0PGmBCaPXs2J510Eo0aNSrZpqq88sorXHnllQFGlvp86Qi89NEWuAWxO6vqNu+l\nRUDTKG/pAfxHVWMWRTLGpLYpU6Yc9IW/YMECGjZs6Ov4uAk4fTRi+3jgE1V9uozjWfpoiqfVxWLt\nTh3RUicB9u/fz2WXXcaECRNIS0ujVq1aADzxxBOkp6fzi1/8IplhBmLXrl0l7fZDhU0f9banAVuA\nhvEe29JHw8Xanfpef/117dmzp6r+1O79+/drgwYNdO3atQFGljx+f96UkT6alOl7EemjfTQifdTT\nB3c1sDEZsRhjKp7JkycfNCz0r3/9i9atW9O0abTRZJNIvs8jiJU+GuFKYLLfcRhjKqbdu3fz7rvv\ncskllxywPdo9A+OPZFwR3A8cD/zNSxUtUG+cyps/0BO4OQlxGBNq27dvZ8CAASxfvhwRYfz48bz9\n9tuMHTuW+vXdCoYPPfQQffv2TWpcNWvWZOvW0gMF8MILLyQ1jjDz7YpAVTOBq3Dpo/W8cx0F7Csu\nRa2qu1X1eGCXiHwqIjP9iseYsBs8eDC9e/dm5cqVLF26lDZt2gDw29/+ltzcXHJzc5PeCZiKwe8r\ngnhLUQ/G3Uiu43M8xoTSjh07mD9/fslf2WlpaaSlpQUblKkwfOsISs0lGK+qC72XDphLICJNgfOB\nvwB3xHPsvfsLybznzcQGXAnc2b6A66zdoXEk7S5d6nj16tXUr1+f66+/nqVLl9KxY0dGjnSl3J9+\n+mkmTpxIp06dGDFiBMcee+wRx24qF9/mEUDcpainAg/jSlIMUdULYhzL5hGkYF55PKzdh650vn5e\nXh4DBw5k1KhRtG3bllGjRlGzZk0uuugi6tatW3LPYOvWrdx9990JiP7w+Z1PX1Gl5DwCjWMuAXAB\n8Dfv9xxgZjzHtXkE4WLtPnIbNmzQjIyMkufz58/Xvn37HrDP6tWrtV27dgk75+Gyz9sfBF2GGmKW\noj4LuNC7cpgCnCMiLyUrJmPColGjRjRr1qykoufs2bNp27YtGzZsKNln+vTpZGVlBRWiCVCyJpRF\nnUugqvcC93r75OCGhq5ORkzGVDSZmZnUrl2bo446iqpVqzJ8+HAuv/zyhJVjHjVqFP3792ffvn20\naNGCCRMmMGjQIHJzcxERMjMzGTNmTCKbZCoJP28WDwKa4KqQbgPqAu+KyFpcBdKLgYlAQ9xSlXP8\nisWYymLu3LmccMIJAMybN49//OMfJa8daTnm7OxsFi9efMC2SZMmHfbxTOrw84pgIC5rqHTq6DBV\n7SwijYE7VfUTEakNLAEu8jEeYyot9coxz5ljfy+ZxAusDLWqblDVT7zfd+JuIqf7EY8xlYGI0KtX\nLzp27HjQalRWjtn4qaKUoc4E5gNZqvp9jONZ+qilUaaMaOWYN2/eTP369dm2bRtDhgzhV7/6FV26\ndAGsHHMYpGT6KPGXoa6FGxa6JN5jW/pouISx3Q888IDecsstqmrlmMMi5dNHY6SOIiLVgNeAl1V1\nWjJiMaYi2r17Nzt37iz5/Z133uHEE08ErByz8Z/v6aOxUkfFlSJ9Hncj+XG/4zCmItu4cSMXX3wx\nAAUFBVx11VWcccYZgJVjNv5LxhVBZBnqXBEpzl87C7gGN4ks13tY6UMTSi1atGDHjh0UFRVRrVo1\npk+fDsDll19Obm4uzz77LJmZmWRnZwccqUlFfl4RPA4sAFoDy3AlqHcCtwKo6r9F5FjckFEWbi7B\ntuiHMiYc/JxHYEwsfs8jKK8E9UjgLVW9TETSgGN8jMeYSkttHoHxkS8dQTwlqEWkLtAVuA5AVfcB\n++I5vpWhDpdUbHfpMtHw0zwCEeHmm2+mZcuWJa/ZPALjp8DmEYhINu7q4AvgNFwK6WBV3R3jeDaP\nIAXz6eORiu22eQSx2TwCf1TIeQRAJ6AAN/MY3DDRn+I5ts0jCJcwttvmEYRPWOcR5AP5qvqh93wq\ncHoy4jGmorF5BCZIvncEZZSg/hZYKyKtvE09cMNExqSszMxM2rdvT3Z2Np06uav0YcOG0aJFCxo0\naECNGjVo27Yt559/vs0jMEmTjPUIIucRgBsOmohLIz0e+FxE9uNuFI9OQjzGBCoyRbTYXXfdxZAh\nQw7YNm/ePICSBeeN8YtvHYGqZnq/DvAeJURkJS619GTKWKfYGGOM/5K2VGWxUqmlHZJ9fmOCFKvU\n9NNPP82pp57KDTfcwLZtNq/SJJdv6aNlntRLLcXNKH4Nd+N4Pe7q4PMY77H00RRMo4xHZW13PCmi\ngwYNolmzZtStWxcRYfz48WzdupW7777b0ihDJiXTR8t64KWWAnWAWt62vsBX8bzf0kfDJVXb/cAD\nD+hjjz12wLbVq1dru3btVDV1210ea7c/CDp9NBZV/V5Vd3m/zwKqicgJ5bzNmEopWopoVlYWGzZs\nKNln+vTpZGVlBRWiCalkZA3FJCKNgI2qqiJyBu6exdZy3mZMpRSt1HTv3r255ppryM3NRUTIzMxk\nzJgxAUdqwibQjgC4DLhVRAqAvcAV3iWMMYetsLCQTp06kZ6ezsyZM+nfvz+LFy+mWrVqnHHGGYwZ\nM4Zq1aolPa4WLVqwdOnSg7ZPmjQp6bEYEymooaHiEtV/AgpxJairBhiPSSEjR46kTZs2Jc/79+/P\nypUrWbZsGXv37mXcuHEBRmdMxRPUF+9AoCfQDDhNVbOBG3BlKIw5bPn5+bz55psMGPDT1JW+ffsi\nIogIZ5xxBvn5+QFGaEzFk/ShoSglqp/wXqqJuzIol5WhDpdY7Y5Wyvn222/n0UcfLbkpG2n//v1M\nmjSJkSNH+hKnMZVV0jsCVb1FRHoD3VV1i4hcDDwMNAAO/j/bU2oeAfe3L0hKvBVJwxruSzFsYrW7\nuARDsQ8++ID9+/ezc+dOcnNz2bp16wH7DB8+nBYtWlBYWHjQeyuiXbt2VYo4E83aHYBYeaV+PihV\notrb1hX4Vzzvt3kE4RJvu++55x5NT0/XjIwMbdiwodaoUUP79++vqqrDhg3Tfv36aWFhoY+RJpZ9\n3uES2nkEkVR1PtDC5hGYw/Xwww+Tn5/PmjVrmDJlCueccw4vvfQS48aN4+2332by5MlUqVJh/pM3\npsII9P8KETlZvJKkInI6cDQ2j8AcosLCQjp06MAFF7jahU8//TT9+/fnzTffZMuWLdxyyy1s3LiR\nM888k+zsbB588MGAIzamYglqHkFtYCGwG2guIrVw5alv8y5hjIlbcbro999/D8BZZ53F+++/T05O\nDuAmbxljYgvqimAzcA5wH/ARUB23MM3NAcVjKqlo6aIdOnQgMzMzuKCMqWSCLkM9HZjo3ctYBNQT\nkcbJjslUXsXpojb2b8zhCzR9FHgBWBvxcj6QDmwo/b7S6aOjXp7hf7AVTMMahL7dkaWdy0sX/eGH\nH3j//fepW/fgctCVgaVRhkto00eBmcDZEdtnA53Ke7+lj4ZLrHaXlS6qqpqRkaGbN29OUpSJZ593\nuIQ5fXQdrsxEsabeNmPKFStd1BhzaILuCN4ArhWnC7BDVQ8aFjLmUDz11FM0bdqU/Px8Tj311ANu\nJBtjDhZ0RzAL+BpYBYzFFaMzSbZ27Vq6d+9O27Ztadeu3QG1eEaNGkXr1q1p164dQ4cODTDKsuXk\n5DBz5kwABg0aRH5+PgUFBaxfv96qjRpTDt9uFovIIOBWoDWwDBBgJ3CrqmZ6+4wHLgA2qWp7v2Ix\nZatatSojRozg9NNPZ+fOnXTs2JGePXuyceNGZsyYwdKlSzn66KPZtGlT0KEaY3zgZ9bQQOBcoDmw\nQlW3iUgf4Dmgs7fPC8DTwEQf4zDlaNy4MY0bu6zd2rVr06ZNG9atW8fYsWO55557OProowFo0KBB\nkGEaY3ziS0cQpdT0Qu+lRbgbwoCrLyQimYd6fCtDfWSilW8ueW3NGj799FM6d+7MXXfdxYIFC7jv\nvvuoXr06w4cP52c/+9kRn98YU7H40hFoqVLTES/diOscDpmVoU5cGepYucp79+5l8ODBDBgwgE8+\n+YQdO3awbNkyHnnkEVauXMmFF17I3//+d7zyUEljeeXhYu0OQKy80iN9UKrUNG4C2Qrg+FL7ZQLL\nD+XYNo8g8fbt26e9evXSESNGlGw777zzdM6cOSXPW7RooZs2bfIthlgsrzxcrN3+IOh5BCJyKm4Z\nyn6qatVFKxhV5cYbb6RNmzbccccdJdsvuugi5s6dC8CXX37Jvn37OOEEqxJuTKrxvcSEiDQHpgHX\nqOqXfp/PHGjt2rVce+21bNy4ERHhpptuYvDgwfzhD39gxowZVKlShWrVqrF48WLat29PdnY2AA89\n9BA33HADN9xwA1lZWaSlpfHiiy8mfVjIGOO/ZNQauh84Hvib9yVSgMsSuhWoBTQEqonIduBOVX0+\nCTGFRqzU0Lvuuos//elPgJuA1bFjR5599tmD3m8zdY1Jfb51BOrNFQAGeI8SIrISl1q6D8gALgK2\nWSeQeLFSQ9u2bVuyz+7du+0vfWNCLOnVR6Oklj4hIrHzGU3CRKaGAtx3331MnDiRunXrltwLMMaE\nj2gAC4KJyBpcldEt3vNhwC5VHV7GeyLTRzve/+TYJERasTSsARv3lr1PZJnmSMWpoVdffTVdu3Y9\n4LWXX36Zffv2cf311ycq1ITatWsXtWrVCjqMpLN2h4vf7e7evfsSVe0U9cVY6UR+Pjg4tXQYMCTe\n91v66KGJlhoa6b///a+2a9fuCCLzl6UThou12x8EnT5qgqMxUkO/+uqrkt9nzJhB69atgwjPGFMB\nBLV4vUmS999/n0mTJh2UGvr888+Tl5dHlSpVyMjIiJoxZIwJh0A7AhFpBCwG6gBFInI70FZVvw8y\nrsoo1nyBDRs20LZtW5YvX85HH31Ep05uiLBv374BR2yMqSiC6ggeBxbg1iL4GDgJ+AG4wTqBwxNr\nvkBWVhbTpk3j5ptvDjpEY0wFFVRHUFyiejAuW+hiEWkNjAZ6BBRTpRZrvkDPnj0DjswYU9EFPY+g\nBdAbQFVXikimiDRU1Y1lHcPKUMdfStoYY8qT9I5AI0pUA3cAlwALROQM3CzjpsBBHYGVoT6wDHW8\npaSLbd++nSVLlrBr165khJpQVpY4XKzdAYiVV+rnA28eAe4m8QQgF5iEu1+QXd77bR5BdGXNF+jW\nrZt+/PHHPkXmL8srDxdrtz8oYx5BoFlD6m4MXw8grtjNatwNZHOINMZ8AWOMKU/Q6aP1gD2qug9X\nmG6+WtbQQW644QZmzpxJzZo1Wb16NQC5ubnccsst/PDDD1StWpWbbrop6nyBH3/8kdtuu43Nmzdz\n/vnnk52dzdtvvx1kc4wxFYyvHYGIDMKVm/4CaAKcDtwXsctpwFve1cA+4Bk/46msrrvuOn7zm99w\n6aWXlmwbOnQoDzzwAH369GHWrFk8+uijxcNuB7n44ouTFaoxphLy+4qgOE00stx0SYlqEZkP1FfV\nXSJSDfi3iHRR1UU+x1WpdO3alTVr1hywTUT4/nt38bRjxw6aNGkSQGTGmFTgW0cQT7lp7wZGcRpL\nNe+R/HKoldCTTz7Jeeedx5AhQygqKmLhwoVBh2SMqaQOuSMQkWOBZqr6WVn7aUSaqHrlpmMc7yhg\nCXAyMFpVP4yx3wHpo6NennGooVcKscpIf/vttxQVFZWklz311FPceOONdOvWjblz53LJJZcwYsSI\nJEaaPJZOGC7W7gDESifSA9M95+FSPY/DZfZ8CDwex/vWEGe5aaAeMBfIKu+4YUwfXb16tWZmZpY8\nr1OnjhYVFamqalFRkdauXTuo0Hxn6YThYu32BwkoQ11XXTbPJcBEVe2MG/tPGFXd7nUEvRN53FTV\npEkT3nvvPQDmzJnDKaecEnBExpjKKt6hoaoi0hj4BQdm/RwREakP7FfV7SJSA+gJ/DVRx08VV155\nJfPmzWPz5s00bdqUP/7xj4wdO5bBgwdTUFBA9erVee6554IO0xhTScXbETwIvA28r6ofi0gL4Kty\n3lMiVrlpoDHwonefoArwiqrOPJQGVGbF8wMaNGjA8uXLARg2bBhjx46lfv36gJsLMHnyZMCVlcjJ\nySl5/5IlS5IeszEm9cQ1NKSqr6rqqap6q/f8a1W9tKz3eHMI9gJjgOlAfeBBVa2nqk1xncBEQIAi\noDkQqslk1113HW+99dZB23/729+Sm5tLbm6urRtgjPFdXFcEItISN9mroapmicipwIWq+ucy3hZ1\nDkExVc0Dsr3jHwWsw3UYoRFtfoAxxiRbvENDY4G7cH/do6qficjfgagdQTxzCErpAfxHVf8bTzCV\ntQx1WaWjIz399NNMnDiRTp06MWLECI499lifIzPGhJlojLIEB+wk8rGq/kxEPlXVDt62XFXNLuM9\na4BO6s0hEJFhuEVohkfZdzzwiao+XcbxIucRdLz/ybHlxl3RRJsj8O2333LvvfcyYcIEAL777jvq\n1q2LiDB+/Hi2bt3K3XffDbg841q1aiU15orA2h0u1m5/dO/efYmqdor6Yqy8Uj0wx///cMtJfuI9\nvwz4v3Les4Y45hAAacAW3LBTXPGk0jyC1atXa7t27eJ6zfKrw8XaHS6VoQz1r4HngNYisg43qaz/\nofdJUfXxOpgyVyULiw0bNpQsOTl9+nSysrICjsgYk+rK7QhEpApuiOdcEakJVFHVnQmM4UpgcgKP\nVyFESw296667+Oc//0laWhonnXQSVapUYeHChWzZsqVkfsC8efPIzc1FRMjMzGTMmDEBt8QYk+rK\n7QhUtUhEhuJy/Hcf4vF/JSLX45afTAOOEpHfA81V9XuvY/k5cJqI3AksA65X1R8O8TwVTnHp6Guv\nvbZkW8+ePXn44YepWrVqybj/a6+9dsD7brzxxqTGaYwx8ZaY+JeIDBGRZiJyXPGjrDeoKzX9S+Ac\nIBM4E3gI+LP+tPhMPWATcLqqZgFHAVccejMqnq5du3LccQf+E/Xq1YuqVV3f26VLF/Lz84MIzRhj\nDhBvR3A57j7BfFyl0CW4mcIxlUoh7a+qHwP7o+xaFaghIlWBY4D1ccZUqY0fP54+ffoEHYYxxsR3\ns1hVTzzUA2scZahVdZ2IDAe+wc1CfkdV34m2b0UvQx0rNXT37t0HlZZ96aWX2L59O+np6YdUdtbK\n84aLtTtcgmx3vDOLr422XVUnHsnJvbUN+gEnAtuBV0XkalV9Kcq5nsNlLtGqVSu9rX+/Izl1UqxZ\ns4aaNWseUB/ohRde4PPPP2f27Nkcc8wxh3S80rWGwsLaHS7W7uSLN330ZxG/V8fNBP4EVyvoSJwL\nrFbVzQAiMg34H+CgjiAVvPXWWzz66KO89957h9wJGGOMX+IdGrot8rmI1AOmJOD83wBdROQY3NBQ\nD8q591BZFJeOjkwNffjhh/nxxx/p2bMn4G4YP/vsswFHaowJu8Nds3g3bjgnLrHKUKvqhyIyFXd1\nUQB8ijf8U1lEmy/w3XffsWXLFmrVqkVWVhavvPIKxx57rKWGGmMqpLiyhkTknyLyhveYCeQBr8fx\n1seBBcAG4Dvgv8AXwPnePILquJnFP+LKUX+tqj8eRjsCE62U9COPPEKPHj346quv6NGjB4888khA\n0RljTPnivSKILBRXAPxXVeNJgi8uRd0cWKGq20SkD+6v/s64DuAcVd0lItWAf4vI/6nqovibEKxo\npaRnzJhRcvf/l7/8JTk5Ofz1r7bwmjGmYoq3I+irqndHbhCRv5beVur10qWoF3ovLcLNNMYrhLTL\n217Ne5RbDjXIMtTxlJLeuHFjSb2gRo0asXGjlVEyxlRc8XYEPYHSX/p9omwrUcY8ghtxnQNQsijN\nEuBkYLSqfhjteKXnEdzfvthfeS4AABh9SURBVCDO0BMrWp5v6fkCBQUFB+xXWFiYkPxgy68OF2t3\nuATa7lhlSd0f69yKq/+zG/gs4rEaeKms92r0UtTdgRXA8VH2rQfMBbLKO25FK0Ndulx0y5Ytdf36\n9aqqun79ek1UvFaeN1ys3eESZBnq8m4W/x1XFO4N72fxo6OqXn0oHY63vOU4oJ+qbo3SIW33OoLe\nh3LciujCCy/kxRdfBODFF1+kX7+KP/nNGBNeZQ4NqeoOYAeuVDQi0gA3oayWiNRS1W/iOYmINAem\nAdeo6pcR2+sD+1V1u4jUwA1BVfi7qiNHjmTs2LGoKkcffTQbNmw4YL7APffcwy9+8Quef/55MjIy\neOWVV4IO2RhjYoq3xMTPcamgTXDVQjNwQzztynlrbWAh7iZwM1xW0AZgg7ol0xoD00SkKS599D1V\nnXk4DUmW5cuXM3bsWD766CPS0tLo3bs3r7zyCieffPIB+82ePTugCI0x5tDEW330z0AX4Et1Beh6\n4LJ/yrMZV4a6M64M9cPAE/rTupmf4zqAtrhOo6GItI0//ORbsWIFnTt35phjjqFq1ap069aNadOm\nBR2WMcYctng7gv3euH4VEamiqnOB6Isge+IsQ30GsEpVv1bVfbiyFRV6QD0rK4sFCxawdetW9uzZ\nw6xZs1i7dm3QYRljzGGLN310u4jUws0SfllENuEyiWLSOMpQA+lA5LdoPu7q4SBBlqEuXWK6X79+\nnHnmmdSoUYPMzEw2bNiQlLQvS6sLF2t3uFT4MtS4v9L3ArfjFq2vCzzoV1DRaAUqQ52Tk8Njjz0G\nwO9+9zuaNm2alPKxVp43XKzd4VLhy1Cr6m4RyQBOUdUXvWqhRyXg/OtwN5GLNfW2VWibNm2iQYMG\nfPPNN0ybNo1FiypNRQxjjDlIvFlDv8INyxwHnIQb0nkWd9P4SHwMnCIiJ+I6gCuAq47wmL679NJL\n2bp1K9WqVWP06NHUq1cv6JCMMeawxXuz+NfAWcD3AKr6FdAg3pOISCMRyQfuAH4vIvkiUkdVC4Df\nAG/j0lFfUdXPD6UBQbjsssuoUqUKBQUFLFu2LOhwjDHmiMTbEfzoZfUA4C00X25xOH4qQz0ad1P4\naODPqtpUVYs7lVlAG1wnc+YhxB6IyHkES5cuZebMmaxatSrosIwx5rDF2xG8JyK/A2qISE/gVeCf\ncbxvIG628K3AIA4sZx1pMO6KoMKzeQTGmFQTb9bQPbiqocuAm4FZuLpBMUUpQ/2EiBxUw9mbVXw+\n8Bfc0FG5kl2GOrL0dFZWFvfddx9bt26lRo0azJo1i06dypxSYYwxFZq4onQxXhRpHm89oRjvXwN0\nKp5HICLDgF2qOjxin6m4Gce1gSGqekGMY0XOI+h4/5NjDzesQ1Z6HsGbb77JjBkzSuYRVKtWjd/8\n5je+x7Fr1y5q1arl+3kqGmt3uFi7/dG9e/clEVUdDhSrLKnXQXwS8ftrZe0b4/1rOLAM9TDcl33x\n8wuAv3m/5wAz4zluRSpDfe+99+ro0aOTci4rzxsu1u5wCbIMdXlDQxLxe4vD6obKdhZwoYj0xVU1\nrSMiL+khlrhONptHYIxJJeXdLNYYvyeEqt6rLoMoEzeHYE5F7wQAzjzzTKpXr07Lli0555xzbB6B\nMaZSK++K4DQR+R53ZVDD+x3vuapqnXhOIiKNgMVAHaBIRH4PbPS2jQWexJWtiOt4QVq+fDk1atTg\nu+++KylDvWrVqoPKUBtjTGVR3sI0R1RGwvtLv1jT4l9EZCVwLm7h+oVAb1X9xlv4pkKLTB8FStJH\nhw4dGnBkxhhzeOKdR5AwpdJKfw1MUy8zSVU3JTueQ2VlqI0xqabM9FHfTuqllQK/x61e1g6XPjpS\nVSfGeI+lj1paXahYu8MlyPTRoDuCYd7PHkAN4APgfI1Y1ziaVq1aaV5ens9Rxqe4DPXAgQN9P5eV\n5w0Xa3e4+N1uEYnZEcQ7s9gv+cBWVd0N7BaR+cBpQJkdQdAsfdQYk0qC7ghmAE97RezScKuTPRFs\nSOWzMtTGmFQSaEegqitE5C3gM6AIGKeqy4OMKZYnnniCcePGISK0b9+ed999l+rVqwcdljHGHLGk\nZw15HgcWiIgC1wCFuDLUcwOKp0zr1q3jqaeeYvHixSxfvpzCwkKmTJkSdFjGGJMQQV0RDMTNI2gO\nrFDVbSLSB7cmcdTF64NWUFDA3r17qVatGnv27KFJkyZBh2SMMQmR9I4gSnnqhd5Li4iYdFYWv8tQ\nR5adBkhPT2fIkCE0b96cGjVq0KtXL3r16uXb+Y0xJpkCTR9Vrzy1t20I0FpVB8R4T9LmEZSeN7Bz\n504eeOAB7r//fmrVqsWwYcPo1q0bPXv29C2GaCy/Olys3eES5DyCoLOGABCR7riFb86OtY+qPocb\nOqJVq1Z6W/9+SYoOXn31VTp06MBFF10EwPr161m0aFHSc50tvzpcrN3hEmS7g7pZXEJETsWtdtZP\nVbcGHU80zZs3Z9GiRezZswdVZfbs2bRp0ybosIwxJiECvSIQkebANOCa8mYTJ1teXh6XX355yfNV\nq1Zx4oknUr9+fTp06MBNN90UYHTGGJM4QXUEtXFVR6sAxwMTRKQl8LWqnhRQTAdo1aoVubm5ABQW\nFpKens6HH35IRkZGwJEZY0xiBdURbAbOVdV8ETkKeBf4DzA+oHjKNHv2bE466STrBIwxKSnQ9FER\nGY9b+ew14GfJjiVeU6ZM4corrww6DGOM8UXQ1UePBv4OdMddDcxU1akx3uNr+mjplNFi+/fv57LL\nLmPChAkcd9xxCT3nobK0unCxdodLkOmjUVe09/sBrAFOAF4FunjbXgAui+f9LVu21GR5/fXXtWfP\nnkk7X1nmzp0bdAiBsHaHi7XbH8BijfGdGvQ8gk7AFBEB1zH0FZECVX092LB+MnnyZBsWMsaktKCr\nj55Y/LuIvIAbGqowncDu3bt59913GTNmTNChGGOMbwKfUFZR5eXlcdZZZ9GsWTO6detGnTp1ePLJ\nJ4MOyxhjEs63KwIRGQTcCnwBNAFOB+5T1eGqmuntUw83qzgLlz1UYf70jjaP4OKLLw44KmOMSTw/\nh4aKS03vAzKAi6LsMxJ4S1UvE5E04Bgf4zlsNo/AGJPKfOkIopSafkJEzi+1T12gK3AdgKruw3Ua\n5fKjDHXp0tORbB6BMSaV+TaPoHSpaREZBuxS1eHe82xcNdEvcAvWLwEGq1vIPtrxbB6B5VeHirU7\nXFJyHgHeXIGI58OAIRHPOwEFQGfv+UjgT/Ec2+YRhIu1O1ys3f6gjHkEQWYN5QP5qvqh93wq7oZy\nhWLzCIwxqS6wjkBVvwXWikgrb1MP3DBRhZCXl0f79u2ZOnUqjz/+uKWPGmNSlp9ZQ7WBhSLyJdAT\nSAN+EJHbgbaq+j2wFVguIoXAW8D1PsZzSFq1asWyZcsASx81xqQ2PzuCzRycPrpNvZvFnseBB4GJ\nqhotvbRCsPRRY0wq82VoqFT6aH9V/RjYX3o/VZ0PfOdHDIlk6aPGmFQWWPpoxH6ZuBpDWeUcz9JH\nLa0uVKzd4RJk+mjQ1UfjpqrP4eYd0KpVK72tf7+knHfGjBl07tyZSy65JCnnK8u8efPIyckJOoyk\ns3aHi7U7+azoXDksfdQYk+qsIyhDcRnqinA1YIwxfvF9aEhEGgGLgTpAUWT6qIhMBnKAE0QkH3hA\nVZ/3O6aybN++nQEDBrB8+XJEhJkzZ1K3bvT7B8YYkwp86wjUKzXtaRr5mogMEpFbgZW4TqK5F0uR\nX/HEa/DgwfTu3ZupU6eyb98+9uzZE3RIxhjjq6BuFheXqL4WqKuqPxeR+kCeiLysrhJp0u3YsYP5\n8+fzwgsvAJCWlkZaWloQoRhjTNIkvSMoNcfg70BtcYsW18LNKSgo7xiJKkNduvT06tWrqV+/Ptdf\nfz1Lly6lY8eOjBw5kpo1ax7xuYwxpqLybR5BmSf15hgAPwJvAK1xJSkuV9Wo3/B+zCMoPXcgLy+P\ngQMHMmrUKNq2bcuoUaOoWbMmN9xwwxGfKxEsvzpcrN3hkpJlqMt64JWoBi4DngAEOBlYDdQp7/1+\nlaHesGGDZmRklDyfP3++9u3b15dzHQ4rzxsu1u5wCWsZanBF5qZ5ca7CdQStgwqmUaNGNGvWjLy8\nPMDVGGrbtm1Q4RhjTFIEPbP4G1z56QUi0hBoBXwdZEAPPfQQXbp0Yc+ePaSlpTF16tQgwzHGGN8F\n1RHUBhbi0koLRORu3PBQGgGnkI4bN47HHnuMAQMGWPqoMSYUguoINgPnqmp+8QYR+TnwW1UNrBqp\npY8aY8Io6fcIItNHReS3ES9dCUxOdjyRItNHO3TowIABA9i9e3eQIRljjO8CTR/Vn0pUH4Nbw/jk\nWFcElj5qaXVhY+0Ol9Cmj0Y8vxz4Z7zvt/TRcLF2h4u12x9U4PTRYlcQ8LAQWPqoMSacgk4fRUTq\nAt2Aq4OOBWDUqFH079+fffv20aJFCyZMmBB0SMYY46vAOwLgYuAdVU36XdnCwkI6depEeno6M2fO\nBCA7O5vFixcnOxRjjAmMb0NDXqnpFSLymoh8ICI/isgQcCWqVXWLd9P4TqC1iCT923fkyJG0adMm\n2ac1xpgKxc97BAOBnsCtwCBgeIz9uqtqtsa6m+2T/Px83nzzTQYMGJDM0xpjTIXjy9BQqVLT41X1\nCRE5v5y3xe1Qy1CXLjcNcPvtt/Poo4+yc+fORIVljDGVki8dgareIiK9cX/tbylrV+AdEVFgjKo+\nF2vHUvMIuL99ucsWlJg3b94Bzz/44AP279/Pzp07yc3NZevWrQftUxHt2rWrUsSZaNbucLF2ByBW\nXumRPjh4rsAwYEipfdK9nw2ApUDXeI59pPMI7rnnHk1PT9eMjAxt2LCh1qhRQ/v3739Ex0wGy68O\nF2t3uIR2HoGqrvN+bgKmA2ck47wPP/ww+fn5rFmzhilTpnDOOefw0ksvJePUxhhT4QTWEYhITRGp\nXfw70AtYnshzrF27lu7du9O2bVvatWvHyJEjE3l4Y4xJCX7OI6gNLBSRL3HZQ2nADyJyO9AWt0LZ\nAhE5DleCeraqvpXIAKpWrcqIESM4/fTT2blzJx07dqRnz54HzBbOyckhJycnkac1xphKxc+OYDNw\nLrAPyAAuArap6nAAEWkObANO8fZ5S0ROVrdSWUI0btyYxo0bA1C7dm3atGnDunXrrGyEMcZE8GVo\nqFT6aH9V/RjYX2q3NsCHqrpHVQuA94BL/IgHYM2aNXz66ad07tzZr1MYY0yl5FsZ6iilpocBuyKu\nCNoAM4Azgb3AbNxd7dtiHK/cMtSly0oX27t3L4MHD+bqq6+ma9euR9awAFl53nCxdodLkGWoA6s1\npKorROSvwDvAbiAXKCxj/+eA5wBatWqlt/XvF9d59u/fzwUXXMAtt9zCHXfcceSBB2jevHmhvJ9h\n7Q4Xa3fyBZ0++ryqdlTVrrj7BV8m+PjceOONtGnTptJ3AsYY45dAOwIRaeD9bI67P/D3RB7//fff\nZ9KkScyZM4fs7Gyys7OZNWtWIk9hjDGVnu9DQyLSCFgM1AGKitNHVfV74DUROR53I/nXqro9kefO\nyMggJyeHjRs3IiLcdNNN9O3bN5GnMMaYSs+3KwJVzQSuAuYC6biSE2uBb4ATvX3+F7gDqA6MEZF7\nEhlD8TyCL774gkWLFjF69Gi++OKLRJ7CGGMqPb+HhopLUZ8FdFPV9sCf8G76ishRwGigD26S2ZUi\nkrAk/8aNG3P66acDB84jMMYY8xPfhoailKJe6L20CGjq/X4GsEpVv/beMwXoB5T5Z3usMtTRyk2X\nvGbzCIwxJirf5hHAwXMJvG1DgNaqOkBELgN6q+oA77VrgM6q+psox7J5BJZfHSrW7nAJzTwCEekO\n3AicfajvtXkEll8dNtbucAmy3UnrCETkVGAc0EdVt3qb1wHNInZr6m1LCJtHYIwx5UvKPAJvnsA0\n4BpVjZw09jFwioicKCJpwBXAG4k677Rp05g0aRLPPvss1atXJz093eYRGGNMKb51BCIyCGgCTMB9\n4Z8EvCoiuSKyWESaAe/irkpWAuuBV1T180TF8D//8z8sWbKEH374gc2bN1OzZk0yMzMTdXhjjEkJ\nfg4NDcRlDcUqQ90YuFNVP/EWqFmCW6UsYawMtTHGlC+wMtSqukFVP/F+3wmswE0884WljxpjTHSB\nlaEutW8mMB/I8kpPRDuepY9aWl2oWLvDJcj00agr2ifigSspcULE82HAkCj71cINC10S77Fbtmyp\n8dq3b5/26tVLR4wYEfd7Kqq5c+cGHUIgrN3hYu32B269l6jfqUFXH60GvAa8rKrTEn18tfRRY4wp\nV2AdgYgI8DywQlUf9+McVobaGGPKF1gZauBU4BpgmYjkerv/TlUT9k199tlnFw8/GWOMicG3jkBd\nGepiTaPs8m9A/Dq/McaY+AR6j8AYY0zwrCMwxpiQ87UMtV9EZCeQF3QcATgB2FLuXqnH2h0u1m5/\nZKhq/WgvJLUMdQLlaayJESlMRBZbu8PD2h0uQbbbhoaMMSbkrCMwxpiQq6wdwXNBBxAQa3e4WLvD\nJbB2V8qbxcYYYxKnsl4RGGOMSRDrCIwxJuQqVUcgIr1FJE9EVonIPUHH4xcRaSYic0XkCxH5XEQG\ne9uPE5F3ReQr7+exQcfqBxE5SkQ+FZGZ3vMTReRD73P/h7e+dUoRkXoiMlVEVorIChE5Mwyft4j8\n1vtvfLmITBaR6qn6eYvIeBHZJCLLI7ZF/YzFecr7N/hMRE73M7ZK0xGIyFHAaKAPrmjdlSKSqmtO\nFuCW8WwLdAF+7bX1HmC2qp4CzPaep6LBuBXriv0VeEJVTwa2ATcGEpW/RgJvqWpr4DRc+1P68xaR\ndGAQbgGrLOAo4ApS9/N+Aehdalusz7gPcIr3uAl4xs/AKk1HAJwBrFLVr1V1HzAF6BdwTL7Q2Mt4\n9gNe9HZ7EbcOdEoRkabA+cA477kA5wBTvV1Srt0iUhfoiivLjqruU9XthODzxk1qrSEiVYFjgA2k\n6OetqvOB70ptjvUZ9wMmemvKLALqeeu8+6IydQTpwNqI5/n4uMZxReEt49kB+BBoqKobvJe+BRoG\nFJafngSGAkXe8+OB7apa4D1Pxc/9RGAzMMEbEhsnIjVJ8c9bVdcBw4FvcB3ADtxqhan+eUeK9Rkn\n9fuuMnUEoSMitXAruN2updZy9paeS6ncXxG5ANikqkuCjiXJqgKnA8+oagdgN6WGgVL08z4W95fv\niUAToCYHD52ERpCfcWXqCNYBzSKeN/W2paQYy3huLL489H5uCio+n5wFXCgia3BDf+fgxs7reUMH\nkJqfez6Qr6ofes+n4jqGVP+8zwVWq+pmVd0PTMP9N5Dqn3ekWJ9xUr/vKlNH8DFwipdRkIa7qfRG\nwDH5ooxlPN8Afun9/ktgRrJj85Oq3quqTb1Fja4A5qhqf2AucJm3Wyq2+1tgrYi08jb1AL4gxT9v\n3JBQFxE5xvtvvrjdKf15lxLrM34DuNbLHuoC7IgYQkq8WKvaV8QH0Bf4EvgPcF/Q8fjYzrNxl4if\nAbneoy9uvHw28BXwL+C4oGP18d8gB5jp/d4C+AhYBbwKHB10fD60Nxu3pOtnwOvAsWH4vIE/AiuB\n5cAk4OhU/byBybh7IftxV4E3xvqMcas3jva+65bhMqt8i81KTBhjTMhVpqEhY4wxPrCOwBhjQs46\nAmOMCTnrCIwxJuSsIzDGmJCrrIvXG5NwIlKIS9UrdpGqrgkoHGOSxtJHjfGIyC5VrZXE81XVn2rq\nGBMYGxoyJk4i0lhE5otIrlc//3+97b1F5BMRWSois71tx4nI614t+UUicqq3fZiITBKR94FJ3toL\nj4nIx96+NwfYRBNSNjRkzE9qiEiu9/tqVb241OtXAW+r6l+89TGOEZH6wFigq6quFpHjvH3/CHyq\nqheJyDnARNzsYXDraZytqntF5CZc+YCficjRwPsi8o6qrvazocZEso7AmJ/sVdXsMl7/GBjvFQR8\nXVVzRSQHmF/8xa2qxfXmzwYu9bbNEZHjRaSO99obqrrX+70XcKqIFNfWqYtbjMQ6ApM01hEYEydV\nnS8iXXEL57wgIo/jVtA6VLsjfhfgNlV9OxExGnM47B6BMXESkQxgo6qOxa2gdjqwCOgqIid6+xQP\nDS0A+nvbcoAtWmpNCc/bwK3eVQYi0tJblMaYpLErAmPilwPcJSL7gV3Ataq62RvnnyYiVXD15HsC\nw3DDSJ8Be/ip1HBp44BM4BOvFPNmUmRpRlN5WPqoMcaEnA0NGWNMyFlHYIwxIWcdgTHGhJx1BMYY\nE3LWERhjTMhZR2CMMSFnHYExxoTc/weTyUv6Wdu4gQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_REzjOrwdDFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "77f55658-2185-4c50-8257-b8c22a572b03"
      },
      "source": [
        "feature_importance.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>fscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>m_bb</td>\n",
              "      <td>0.139647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>m_wbb</td>\n",
              "      <td>0.090148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>m_wwbb</td>\n",
              "      <td>0.078791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>m_jjj</td>\n",
              "      <td>0.075887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>jet1_pt</td>\n",
              "      <td>0.072598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    feature    fscore\n",
              "25     m_bb  0.139647\n",
              "26    m_wbb  0.090148\n",
              "27   m_wwbb  0.078791\n",
              "22    m_jjj  0.075887\n",
              "5   jet1_pt  0.072598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWiqfCYZdxai",
        "colab_type": "text"
      },
      "source": [
        "## Test algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTY8ZTRaeIbK",
        "colab_type": "text"
      },
      "source": [
        "### Set up Bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JadlZZmLd7O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "import skopt\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import gp_minimize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def fit_lreg(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "    predictions = model_bdt.clf(X_test)[:,1]\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "\n",
        "def fit_xgboost(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping_rounds = 10\n",
        "    # Define model\n",
        "    model_bdt = xgb.XGBClassifier(n_jobs = 4, n_estimators = p['n_estimators'], learning_rate = p['learning_rate'],\n",
        "                            max_depth = p['max_depth'], min_child_weight = p['min_child_weight'])\n",
        "    # Last in list is used for early stopping\n",
        "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "    # Fit with early stopping\n",
        "    #model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
        "    #                early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
        "    model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"])\n",
        "    predictions = model_bdt.predict_proba(X_test)[:,1]\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "def fit_keras(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    # Early stopping\n",
        "    patience = 5\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=patience)\n",
        "    \n",
        "    # Define model\n",
        "    model = create_model(X_train.shape[1], p['dense_layers'], p['dense_units'], 0., \n",
        "                            #p['regulizer_value'], \n",
        "                            p['dropout_value'], \n",
        "                            p['learning_rate'])\n",
        "    \n",
        "    #history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100,# p['batch_size'], \n",
        "    #                    epochs=1000, verbose=0, callbacks=[es])\n",
        "\n",
        "    history = model.fit(X_train, y_train, batch_size = p['batch_size'], epochs=p['epochs'], verbose=0)\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "\n",
        "def optimize( algo, dimensions, initial_param, data, cv = False, kfold_splits = 5, num_calls=12, random_state = 42): \n",
        "\n",
        "    prior_values = []\n",
        "    prior_names = []\n",
        "    for var in dimensions:\n",
        "        name = var.name\n",
        "        print( name )\n",
        "        prior_names.append(name)\n",
        "        prior_values.append(initial_param[name])\n",
        "\n",
        "    global num_skopt_call\n",
        "    num_skopt_call = 0\n",
        "    #errors = []\n",
        "\n",
        "    @use_named_args(dimensions)\n",
        "    def fitness(**p): \n",
        "\n",
        "        global num_skopt_call\n",
        "\n",
        "        print('\\n \\t ::: {} SKOPT CALL ::: \\n'.format(num_skopt_call+1))\n",
        "        print(p)\n",
        "\n",
        "        reduced_feat = feature_importance.iloc[0:p['n_feat']]\n",
        "        reduced_feat = list(reduced_feat['feature'])\n",
        "        data_red = data[reduced_feat]\n",
        "        features = data_red.values\n",
        "        labels = data[['label']].values.ravel()\n",
        "\n",
        "        if cv == False:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=random_state)\n",
        "            if algo == 'xgboost':\n",
        "                score = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
        "            if algo == 'keras':\n",
        "                score = fit_keras(X_train, y_train, X_test, y_test, p)\n",
        "            print(score)\n",
        "\n",
        "        else:\n",
        "            cv_scores = []    \n",
        "            enum = enumerate(KFold(n_splits=kfold_splits, shuffle=True, random_state=random_state).split(features,labels))\n",
        "            for i,(index_train, index_valid) in enum:\n",
        "                X_train, X_test = features[ index_train ], features[ index_valid ]\n",
        "                y_train, y_test = labels[ index_train ], labels[ index_valid ]   \n",
        "                if algo == 'xgboost':\n",
        "                    score = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
        "                if algo == 'keras':\n",
        "                    score = fit_keras(X_train, y_train, X_test, y_test, p)\n",
        "                print(score)\n",
        "                cv_scores.append(score)\n",
        "                #print( cv_scores )\n",
        "            score = np.mean(cv_scores)\n",
        "            print(score)\n",
        "            print(np.std(cv_scores))\n",
        "\n",
        "        num_skopt_call += 1\n",
        "\n",
        "        return -1*score\n",
        "\n",
        "    search_result = gp_minimize( func = fitness, dimensions = dimensions,\n",
        "                                 acq_func = 'EI', # Expected Improvement\n",
        "                                 n_calls = num_calls, x0 = prior_values )\n",
        "\n",
        "    params = pd.DataFrame(search_result['x_iters'])\n",
        "    params.columns = [*prior_names]\n",
        "    params = params.rename_axis('call').reset_index()\n",
        "    scores = pd.DataFrame(search_result['func_vals'])\n",
        "    scores.columns = ['score']\n",
        "    result = pd.concat([params, scores], axis=1)\n",
        "    result = result.sort_values(by=['score'])\n",
        "    #errors_frame = pd.DataFrame(errors, columns = ['call', 'q_error', 't_error'])\n",
        "    #result = pd.merge(result, errors_frame, on=['call'])   \n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r236T_l7d2AK",
        "colab_type": "text"
      },
      "source": [
        "### 1. XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Oz0bOrMdCs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "# Skopt dimensions\n",
        "skopt_dims = [       \n",
        "    Integer(        low=20,    high=200,                         name='n_estimators'     ),\n",
        "    Real(        low=1e-2, high=1,     prior='log-uniform', name='learning_rate'     ),\n",
        "    Integer(        low=2,    high=20,                         name='max_depth'     ),\n",
        "    Integer(        low=1,    high=30,                         name='min_child_weight'     ),\n",
        "    Real(        low=1e-6, high=1e-2,     prior='log-uniform', name='reg_alpha'     ),\n",
        "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
        "\n",
        "]\n",
        "\n",
        "# Initial parameters\n",
        "init_param = {'n_estimators' : 100, 'learning_rate' : 0.3, 'reg_alpha' : 1e-5, 'max_depth' : 6, 'min_child_weight' : 1, 'n_feat':12 }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUaHPgdeevWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35d3ea31-76b2-441b-9ef0-e9cc87b4794b"
      },
      "source": [
        "search_result = optimize('xgboost', skopt_dims, init_param, data, cv = True, num_calls=50, random_state = 42)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_estimators\n",
            "learning_rate\n",
            "max_depth\n",
            "min_child_weight\n",
            "reg_alpha\n",
            "n_feat\n",
            "\n",
            " \t ::: 1 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 6, 'min_child_weight': 1, 'reg_alpha': 1e-05, 'n_feat': 12}\n",
            "0.7811189147168113\n",
            "0.0068822956674509765\n",
            "\n",
            " \t ::: 2 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 104, 'learning_rate': 0.6179507087969082, 'max_depth': 13, 'min_child_weight': 7, 'reg_alpha': 0.006289449243522464, 'n_feat': 22}\n",
            "0.7566188989617335\n",
            "0.005664474648282307\n",
            "\n",
            " \t ::: 3 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 41, 'learning_rate': 0.03541470984030101, 'max_depth': 17, 'min_child_weight': 3, 'reg_alpha': 1.1639759205860849e-05, 'n_feat': 11}\n",
            "0.7756162446752677\n",
            "0.0078047518754549685\n",
            "\n",
            " \t ::: 4 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 42, 'learning_rate': 0.2219420434019009, 'max_depth': 4, 'min_child_weight': 12, 'reg_alpha': 3.751905220326583e-05, 'n_feat': 14}\n",
            "0.7921974548940319\n",
            "0.00820642051053117\n",
            "\n",
            " \t ::: 5 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 126, 'learning_rate': 0.3231581330284767, 'max_depth': 14, 'min_child_weight': 3, 'reg_alpha': 0.0011928349820128476, 'n_feat': 12}\n",
            "0.7787324444059142\n",
            "0.005909997968733684\n",
            "\n",
            " \t ::: 6 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 160, 'learning_rate': 0.011380263271287711, 'max_depth': 3, 'min_child_weight': 13, 'reg_alpha': 0.00035427278147921173, 'n_feat': 24}\n",
            "0.7549855152478588\n",
            "0.008848683894298975\n",
            "\n",
            " \t ::: 7 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 102, 'learning_rate': 0.0234926097824713, 'max_depth': 16, 'min_child_weight': 5, 'reg_alpha': 3.2752651374509267e-06, 'n_feat': 11}\n",
            "0.7862105566637551\n",
            "0.006594656173422357\n",
            "\n",
            " \t ::: 8 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 114, 'learning_rate': 0.26131001288465494, 'max_depth': 3, 'min_child_weight': 9, 'reg_alpha': 0.0008957563474627504, 'n_feat': 22}\n",
            "0.7904974813034636\n",
            "0.0076727511392985425\n",
            "\n",
            " \t ::: 9 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 130, 'learning_rate': 0.013248134789499983, 'max_depth': 16, 'min_child_weight': 13, 'reg_alpha': 3.384229509926665e-05, 'n_feat': 10}\n",
            "0.7868479042698648\n",
            "0.007394285763638624\n",
            "\n",
            " \t ::: 10 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 88, 'learning_rate': 0.33840866095324235, 'max_depth': 4, 'min_child_weight': 7, 'reg_alpha': 2.5082122836695298e-05, 'n_feat': 21}\n",
            "0.7855283490228727\n",
            "0.007732505014438563\n",
            "\n",
            " \t ::: 11 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 197, 'learning_rate': 0.2956862934751351, 'max_depth': 12, 'min_child_weight': 17, 'reg_alpha': 0.00030313001548459487, 'n_feat': 11}\n",
            "0.7733535202437236\n",
            "0.004201080949968972\n",
            "\n",
            " \t ::: 12 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 0.01, 'max_depth': 20, 'min_child_weight': 1, 'reg_alpha': 0.01, 'n_feat': 7}\n",
            "0.7312413118411005\n",
            "0.008245432109603544\n",
            "\n",
            " \t ::: 13 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 1.0, 'max_depth': 2, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 5}\n",
            "0.7515511344572159\n",
            "0.008892893629440983\n",
            "\n",
            " \t ::: 14 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.03205973188670789, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 0.01, 'n_feat': 27}\n",
            "0.7961883775554148\n",
            "0.007979168539318082\n",
            "\n",
            " \t ::: 15 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 119, 'learning_rate': 0.07101346437998442, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 5}\n",
            "0.760654511514333\n",
            "0.00616987829395461\n",
            "\n",
            " \t ::: 16 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 0.01872755213067912, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 5}\n",
            "0.7513062737336823\n",
            "0.006270902353084549\n",
            "\n",
            " \t ::: 17 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.022904593729207806, 'max_depth': 14, 'min_child_weight': 20, 'reg_alpha': 0.01, 'n_feat': 27}\n",
            "0.7962458463328926\n",
            "0.007913373819699927\n",
            "\n",
            " \t ::: 18 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.9225816294517385, 'max_depth': 18, 'min_child_weight': 3, 'reg_alpha': 1.9313132639688342e-05, 'n_feat': 27}\n",
            "0.7593968157964244\n",
            "0.007755613255843904\n",
            "\n",
            " \t ::: 19 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.0138905496148292, 'max_depth': 20, 'min_child_weight': 1, 'reg_alpha': 0.01, 'n_feat': 27}\n",
            "0.7770731314693485\n",
            "0.00823382311836125\n",
            "\n",
            " \t ::: 20 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.06037601803528898, 'max_depth': 9, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 27}\n",
            "0.7929292433817892\n",
            "0.008662610797972025\n",
            "\n",
            " \t ::: 21 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 0.07623270950122181, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 5}\n",
            "0.7233083692683736\n",
            "0.011242106227576914\n",
            "\n",
            " \t ::: 22 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.05204990495223075, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 15}\n",
            "0.7970443056029091\n",
            "0.004526084684896314\n",
            "\n",
            " \t ::: 23 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 0.0959604576959882, 'max_depth': 2, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 27}\n",
            "0.732767898136129\n",
            "0.011258117176156721\n",
            "\n",
            " \t ::: 24 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 1.1293627410833351e-06, 'n_feat': 27}\n",
            "0.7870265890659367\n",
            "0.008464388463625273\n",
            "\n",
            " \t ::: 25 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.17146064485232476, 'max_depth': 2, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 21}\n",
            "0.7849135970879454\n",
            "0.008505822108756786\n",
            "\n",
            " \t ::: 26 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 109, 'learning_rate': 0.04017045795463585, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 14}\n",
            "0.79773205640099\n",
            "0.007291888005484354\n",
            "\n",
            " \t ::: 27 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 124, 'learning_rate': 0.04908585670900606, 'max_depth': 11, 'min_child_weight': 20, 'reg_alpha': 0.01, 'n_feat': 15}\n",
            "0.7988892183556606\n",
            "0.007168352361444033\n",
            "\n",
            " \t ::: 28 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 106, 'learning_rate': 0.1182223352344852, 'max_depth': 18, 'min_child_weight': 1, 'reg_alpha': 1e-06, 'n_feat': 18}\n",
            "0.7887826457393661\n",
            "0.004446424467006443\n",
            "\n",
            " \t ::: 29 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.05023169947770891, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 0.01, 'n_feat': 15}\n",
            "0.7715542401234067\n",
            "0.01014512533610175\n",
            "\n",
            " \t ::: 30 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 15}\n",
            "0.7895637801870712\n",
            "0.00813882480994337\n",
            "\n",
            " \t ::: 31 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.21858356078872265, 'max_depth': 2, 'min_child_weight': 20, 'reg_alpha': 0.01, 'n_feat': 27}\n",
            "0.7851482975086551\n",
            "0.00760119617928194\n",
            "\n",
            " \t ::: 32 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.05008377021063197, 'max_depth': 18, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 22}\n",
            "0.7948148405098316\n",
            "0.006330403578561059\n",
            "\n",
            " \t ::: 33 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 97, 'learning_rate': 0.16761709583962442, 'max_depth': 2, 'min_child_weight': 20, 'reg_alpha': 1e-06, 'n_feat': 16}\n",
            "0.7781845581524748\n",
            "0.009599529180466623\n",
            "\n",
            " \t ::: 34 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 0.01, 'n_feat': 27}\n",
            "0.7572159646478709\n",
            "0.0059213055260899\n",
            "\n",
            " \t ::: 35 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 65, 'learning_rate': 0.01, 'max_depth': 2, 'min_child_weight': 20, 'reg_alpha': 0.01, 'n_feat': 5}\n",
            "0.7077640779402347\n",
            "0.012413294152695785\n",
            "\n",
            " \t ::: 36 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 171, 'learning_rate': 0.05837726351230183, 'max_depth': 15, 'min_child_weight': 20, 'reg_alpha': 0.0003465366414226276, 'n_feat': 19}\n",
            "0.7953915036497936\n",
            "0.005835398191564026\n",
            "\n",
            " \t ::: 37 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.09027458586172321, 'max_depth': 12, 'min_child_weight': 1, 'reg_alpha': 0.01, 'n_feat': 19}\n",
            "0.7921081177771743\n",
            "0.006021522333526843\n",
            "\n",
            " \t ::: 38 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 0.1706354873766392, 'max_depth': 14, 'min_child_weight': 20, 'reg_alpha': 1.7366661560583812e-06, 'n_feat': 14}\n",
            "0.7902039360577241\n",
            "0.004707145034261667\n",
            "\n",
            " \t ::: 39 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 1.0, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 2.238193483149065e-06, 'n_feat': 15}\n",
            "0.7638309554158436\n",
            "0.008395566530545484\n",
            "\n",
            " \t ::: 40 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 115, 'learning_rate': 0.024141590949705808, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 0.005295939881704602, 'n_feat': 18}\n",
            "0.7935523673250012\n",
            "0.0083268492595625\n",
            "\n",
            " \t ::: 41 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 102, 'learning_rate': 0.07309673114535281, 'max_depth': 12, 'min_child_weight': 9, 'reg_alpha': 1e-06, 'n_feat': 16}\n",
            "0.7953140092727582\n",
            "0.007669556713904368\n",
            "\n",
            " \t ::: 42 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.1090687540439025, 'max_depth': 14, 'min_child_weight': 20, 'reg_alpha': 6.99107700213913e-05, 'n_feat': 27}\n",
            "0.7890407348082731\n",
            "0.007105355918988667\n",
            "\n",
            " \t ::: 43 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.0261939063761721, 'max_depth': 14, 'min_child_weight': 20, 'reg_alpha': 0.00041700683235804207, 'n_feat': 13}\n",
            "0.7981182181625052\n",
            "0.007386715579068648\n",
            "\n",
            " \t ::: 44 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 20, 'learning_rate': 1.0, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 2.250372922100096e-05, 'n_feat': 5}\n",
            "0.7165519819963106\n",
            "0.009171713989661365\n",
            "\n",
            " \t ::: 45 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 34, 'learning_rate': 0.022358755460103626, 'max_depth': 20, 'min_child_weight': 14, 'reg_alpha': 0.004667893363139647, 'n_feat': 26}\n",
            "0.7736067551401768\n",
            "0.007448433429470778\n",
            "\n",
            " \t ::: 46 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 109, 'learning_rate': 0.013801501081240938, 'max_depth': 15, 'min_child_weight': 20, 'reg_alpha': 4.157056023713286e-06, 'n_feat': 16}\n",
            "0.7848175939178873\n",
            "0.00820349307385027\n",
            "\n",
            " \t ::: 47 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 20, 'min_child_weight': 20, 'reg_alpha': 0.0002871036374342557, 'n_feat': 5}\n",
            "0.7620752853924244\n",
            "0.00799098677887051\n",
            "\n",
            " \t ::: 48 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.03518214713064302, 'max_depth': 20, 'min_child_weight': 6, 'reg_alpha': 0.01, 'n_feat': 14}\n",
            "0.7937286413993132\n",
            "0.006691815547815643\n",
            "\n",
            " \t ::: 49 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 119, 'learning_rate': 0.07434209213203438, 'max_depth': 16, 'min_child_weight': 20, 'reg_alpha': 5.915708383851866e-05, 'n_feat': 12}\n",
            "0.7979086853377825\n",
            "0.006239866873216737\n",
            "\n",
            " \t ::: 50 SKOPT CALL ::: \n",
            "\n",
            "{'n_estimators': 200, 'learning_rate': 0.11005800039402217, 'max_depth': 2, 'min_child_weight': 1, 'reg_alpha': 0.01, 'n_feat': 27}\n",
            "0.7811901841638973\n",
            "0.009243995506091562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZuH8bAbIxAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search_result.to_hdf('xgboost.h5', 'frame')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaC2QkDngdWI",
        "colab_type": "text"
      },
      "source": [
        "### 2. Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMJ02LakiRc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Reshape\n",
        "\n",
        "def create_model( n_features, dense_layers, dense_units, regulizer_value, dropout_value, learning_rate ):\n",
        "\n",
        "    m_input = Input(shape = (n_features, ))\n",
        "    m = m_input\n",
        "    \n",
        "    for _ in range(dense_layers):\n",
        "        m = Dense( units=dense_units, activation='relu', \n",
        "                   kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
        "        m = Dropout(dropout_value)(m)\n",
        "\n",
        "    m_output = Dense( units=1, activation='sigmoid', \n",
        "                      kernel_initializer='lecun_normal',\n",
        "                      kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
        "\n",
        "    model = keras.models.Model(inputs=m_input, outputs=m_output)\n",
        "    model.compile( loss = 'binary_crossentropy',\n",
        "                        optimizer = keras.optimizers.Adam(lr=learning_rate) )\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqB7c3v4ipkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimensions = [\n",
        "    Integer(        low=20,    high=200,                         name='epochs'     ),\n",
        "    Integer(     low=1,    high=5,                        name='dense_layers'      ),\n",
        "    Integer(     low=100,    high=1000,                    name='batch_size'      ),\n",
        "    Integer(     low=5,    high=200,                        name='dense_units'       ),\n",
        "    #Real(        low=1e-3, high=0.9,  prior=\"log-uniform\", name='regulizer_value'   ),\n",
        "    Real(        low=1e-3, high=0.5,   prior=\"log-uniform\",                    name='dropout_value'     ),\n",
        "    Real(        low=1e-4, high=1e-1, prior='log-uniform', name='learning_rate'     ),\n",
        "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Initial parameters\n",
        "init_param = {'epochs' : 50 ,'learning_rate' : 1e-2, 'dense_layers' : 3, 'regulizer_value' : 1e-2, 'dropout_value': 0.02, \n",
        "             'dense_units' : 20, 'batch_size' : 100, 'n_feat': 20}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7oIVki7gT9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af6386f1-084b-4855-edf3-22b56e4f38e5"
      },
      "source": [
        "search_result_k = optimize('keras', dimensions, init_param, data, cv = True, num_calls=50, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs\n",
            "dense_layers\n",
            "batch_size\n",
            "dense_units\n",
            "dropout_value\n",
            "learning_rate\n",
            "n_feat\n",
            "\n",
            " \t ::: 1 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 50, 'dense_layers': 3, 'batch_size': 100, 'dense_units': 20, 'dropout_value': 0.02, 'learning_rate': 0.01, 'n_feat': 20}\n",
            "0.7478641197368062\n",
            "0.746250016562703\n",
            "0.7525858743294203\n",
            "0.7572125213346588\n",
            "0.7573090375741859\n",
            "0.7522443139075549\n",
            "0.004594972818457291\n",
            "\n",
            " \t ::: 2 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 144, 'dense_layers': 4, 'batch_size': 665, 'dense_units': 148, 'dropout_value': 0.05453826273784942, 'learning_rate': 0.0008095500745638747, 'n_feat': 10}\n",
            "0.7633003878600044\n",
            "0.7787447896236729\n",
            "0.7698653727731828\n",
            "0.7806238160436634\n",
            "0.7849946874287155\n",
            "0.7755058107458479\n",
            "0.007842329136779274\n",
            "\n",
            " \t ::: 3 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 187, 'dense_layers': 2, 'batch_size': 217, 'dense_units': 181, 'dropout_value': 0.058603859161523206, 'learning_rate': 0.0004935612577472992, 'n_feat': 13}\n",
            "0.764309228907909\n",
            "0.7864018834230719\n",
            "0.7676592133781667\n",
            "0.7771700083150463\n",
            "0.7812861424929666\n",
            "0.775365295303432\n",
            "0.00826728493037226\n",
            "\n",
            " \t ::: 4 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 102, 'dense_layers': 5, 'batch_size': 302, 'dense_units': 144, 'dropout_value': 0.02428503124111991, 'learning_rate': 0.00020063125109950636, 'n_feat': 19}\n",
            "0.6989743324335022\n",
            "0.7228711051710384\n",
            "0.7045446533512045\n",
            "0.7290714031172045\n",
            "0.7087147679476866\n",
            "0.7128352524041273\n",
            "0.011332858933041062\n",
            "\n",
            " \t ::: 5 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 160, 'dense_layers': 5, 'batch_size': 282, 'dense_units': 118, 'dropout_value': 0.3558703928268431, 'learning_rate': 0.004806278992407107, 'n_feat': 19}\n",
            "0.7577626380780865\n",
            "0.7617622065870306\n",
            "0.7528282668422793\n",
            "0.7580225193965652\n",
            "0.7644990175244819\n",
            "0.7589749296856887\n",
            "0.003960875140336988\n",
            "\n",
            " \t ::: 6 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 145, 'dense_layers': 2, 'batch_size': 945, 'dense_units': 17, 'dropout_value': 0.008371204437598492, 'learning_rate': 0.00011749316057944096, 'n_feat': 18}\n",
            "0.6695281749177863\n",
            "0.6652538993602671\n",
            "0.6781419957591936\n",
            "0.6748908103106577\n",
            "0.6833925119757962\n",
            "0.6742414784647401\n",
            "0.006361900499313274\n",
            "\n",
            " \t ::: 7 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 159, 'dense_layers': 3, 'batch_size': 806, 'dense_units': 197, 'dropout_value': 0.001214830999289793, 'learning_rate': 0.002912473917107305, 'n_feat': 18}\n",
            "0.6808348203425358\n",
            "0.7020398499881623\n",
            "0.6845553341228904\n",
            "0.7053272564722947\n",
            "0.6748747643859627\n",
            "0.6895264050623691\n",
            "0.012009820772412054\n",
            "\n",
            " \t ::: 8 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 128, 'dense_layers': 4, 'batch_size': 359, 'dense_units': 139, 'dropout_value': 0.013907301425020785, 'learning_rate': 0.005074321031052858, 'n_feat': 12}\n",
            "0.7408746139339075\n",
            "0.749196052651645\n",
            "0.7323156598064211\n",
            "0.7348609261586361\n",
            "0.7284627009472585\n",
            "0.7371419906995735\n",
            "0.007253408601321555\n",
            "\n",
            " \t ::: 9 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 102, 'dense_layers': 3, 'batch_size': 388, 'dense_units': 76, 'dropout_value': 0.0013767744650950613, 'learning_rate': 0.0014460592692076629, 'n_feat': 26}\n",
            "0.6575670954303626\n",
            "0.6530359996909962\n",
            "0.6541211352520219\n",
            "0.6804102506392583\n",
            "0.6572522350817795\n",
            "0.6604773432188837\n",
            "0.010118958801515724\n",
            "\n",
            " \t ::: 10 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 36, 'dense_layers': 4, 'batch_size': 225, 'dense_units': 177, 'dropout_value': 0.04271355923533369, 'learning_rate': 0.035762905737144524, 'n_feat': 23}\n",
            "0.5\n",
            "0.7132463622679377\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5426492724535875\n",
            "0.08529854490717509\n",
            "\n",
            " \t ::: 11 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 102, 'dense_layers': 5, 'batch_size': 318, 'dense_units': 28, 'dropout_value': 0.03042973730872762, 'learning_rate': 0.015545256443457478, 'n_feat': 18}\n",
            "0.7500031877876978\n",
            "0.7703961873532952\n",
            "0.75918535114162\n",
            "0.7615654794280748\n",
            "0.7595802618467337\n",
            "0.7601460935114843\n",
            "0.0064992431565814275\n",
            "\n",
            " \t ::: 12 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 200, 'dense_layers': 5, 'batch_size': 100, 'dense_units': 121, 'dropout_value': 0.49999999999999994, 'learning_rate': 0.0015716529519433542, 'n_feat': 5}\n",
            "0.7521496315042433\n",
            "0.7605370665790656\n",
            "0.7638300617219593\n",
            "0.762843995973767\n",
            "0.7741616942600218\n",
            "0.7627044900078114\n",
            "0.00705204460032571\n",
            "\n",
            " \t ::: 13 SKOPT CALL ::: \n",
            "\n",
            "{'epochs': 194, 'dense_layers': 1, 'batch_size': 911, 'dense_units': 158, 'dropout_value': 0.49999999999999994, 'learning_rate': 0.0001, 'n_feat': 15}\n",
            "0.6868877416186812\n",
            "0.6963672804991862\n",
            "0.6865116004631335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qDYdijsY1yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHeuKCtY1yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}